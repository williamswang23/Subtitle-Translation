
    <!DOCTYPE html>
    <html lang="zh">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>Document</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 40px; font-size: 22px; }
            p { margin-bottom: 20px; }  // 可以根据需要调整段落间距
        </style>
    </head>
    <body>
	    <p>版权归属于原视频作者，视频地址：https://www.youtube.com/watch?v=cdiD-9MMpb0</p> <p>我认为物理学存在某些漏洞，我们应该努力去发现它们。</p><p>通过排列某种疯狂的量子力学系统，这些系统以某种方式给你缓冲区溢出，或者在浮点运算中给你舍入误差。</p><p>合成人工智能（AI）类似于发展的下一个阶段。</p><p>我不知道它们会引导我们到哪里去，在某个时刻我怀疑</p><p>宇宙就像一个谜题，这些合成AI将揭开这个谜题并</p><p>解开它。</p><p>以下是与安德烈·卡帕西的对话，他曾任特斯拉（Tesla）的AI总监，在此之前在OpenAI和斯坦福大学任职。</p><p>他是人工智能历史上最伟大的科学家、工程师和教育家之一。</p><p>这是莱克斯·弗里德曼的播客节目，为了支持该节目，请查看我们的赞助商，</p><p>现在，亲爱的朋友们，这是安德烈·卡帕斯。</p><p>什么是神经网络，为什么它在学习方面似乎表现出如此惊人的效果？</p><p>什么是神经网络？</p><p>我会说，它是大脑的数学抽象，</p><p>这是它最初的开发方式。</p><p>归根结底，它是一种数学表达式，而且是一种非常简单的数学表达式。</p><p>当你深入了解时，它基本上是一个矩阵乘法的序列，实际上是点积的数学表示，并添加了一些非线性元素，</p><p>所以它是一个非常简单的数学表达式。</p><p>它里面有很多旋钮，很多旋钮，</p><p>这些旋钮大致类似于你大脑中的突触，它们是可训练的、可修改的，</p><p>所以想法是我们需要找到旋钮的设置，使神经网络能够实现你想要的功能，比如图像分类等等。</p><p>所以我认为它并没有太大的神秘之处，</p><p>你可能会认为不想把它与大脑及其工作方式赋予过多的意义，它实际上只是一个复杂的带旋钮的数学表达式，而这些旋钮需要正确的设置，才能做一些有用的事情。</p><p>是的，但是诗歌也只是字母和空格的集合，但它可以让我们有某种感觉，</p><p>同样，当你把大量旋钮放在一起，不管是在大脑内部还是在计算机内部，它们似乎会用它们的力量给我们带来惊喜。</p><p>是的，我认为这是合理的，所以基本上我极大地低估了它的能力，</p><p>因为当这些神经元足够大并在复杂的问题上进行训练时，你确实会得到非常令人惊讶的涌现行为，比如从互联网的大型数据集中进行下一个单词预测，</p><p>这些神经元表现出非常惊人的魔法特性。</p><p>我认为有趣的是，即便是非常简单的数学形式也能展现出如此多的智慧，</p><p>那么你的大脑现在在说话时，是在做下一个单词预测吗？</p><p>还是在做更有趣的事情？</p><p>肯定是在做某种生成型模型，这个模型类似于GPT模型，由你给出的提示触发，</p><p>嗯，是的，你给了我一个提示，我就以生成的方式回应你，或许是自己，</p><p>你是否在从自己的记忆中自动添加额外的提示？</p><p>自动感觉你是在引用某种声明性结构，比如记忆，等等，</p><p>然后，你将它与提示结合在一起，给出了一些信息，</p><p>你刚才说的有多少是你以前说过的？</p><p>基本上没有，</p><p>不，但是如果你实际上搜索所有你一生中说过的话，你可能会发现你以前说过很多相同顺序的词。</p><p>这可能，我确实在使用常见的短语等等，但我将它们重新组合成一个非常独特的句子，</p><p>但是你说得对，确实存在大量的重新组合。</p><p>你没有，说得就像Magnus Carlsen说的，我的评级是2900多，这是相当不错的，</p><p>我认为你没有足够地赞扬神经网络，那么，它们为什么似乎会？</p><p>你对这种涌现行为的最佳直觉是什么？</p><p>这确实很有趣，因为我一方面在低估它们，但同时也觉得在某种程度上我在夸大它们，</p><p>实际上从数学上讲，它们非常简单，但你能从中获得如此多的涌现行为，确实有点不可思议，</p><p>我认为这两个相反的陈述恰好放在一起，</p><p>我认为我们实际上非常擅长优化这些神经网络，而且当你给它们一个足够困难的问题时，它们就被迫在优化中学习到非常有趣的解决方案，</p><p>这些解决方案基本上具有非常有趣的涌现特性。</p><p>旋钮中有智慧和知识。</p><p>所以设在旋钮中的这种表示是什么？  
它在直觉上对你有意义吗？  
大量的旋钮可以容纳一种表示，这种表示捕捉了它所查看的数据中的某些深层智慧。  
确实有很多旋钮，是很多旋钮。  
具体来说，人们现在非常兴奋的一种神经网络是GPT，它实际上只是下一词预测网络。  
你从互联网上获取一系列词语，然后尝试预测下一个词。  
一旦你在足够大的数据集上训练它们后，你基本上可以用任意方式提示这些神经网络，并可以要求它们解决问题，它们会照做。  
例如，你可以让它们看起来像是在尝试解决某个数学问题，它们会根据在互联网上看到的继续提出解决方案，而且这些解决方案通常看起来非常一致，可能是正确的。  </p><p>你还在考虑大脑这一方面吗？  
神经网络是大脑的抽象或数学抽象，你还从生物神经网络中汲取智慧吗？  
或者是更大的问题，你是生物学和生物计算的超级粉丝，生物学中有哪件令你印象深刻的东西是计算机还未做到的？  
我肯定是在这方面更加犹豫的，比你在这个领域的其他人可能会看到的更犹豫一些。  
我觉得尽管神经网络的起源都源自于大脑的启发，但是最终的人工制品是通过一种非常不同的优化过程得到的，而这种优化过程与大脑的优化过程是不一样的。  
所以我认为这种神经网络是一种非常复杂的外星人工制品。  
神经网络的训练结果是一种复杂的外星人工制品，我不做大脑类比，因为产生它的优化过程与大脑不同。  
没有多代理自对抗的设置，进化是一种在大量数据上进行压缩的优化。  </p><p>因此，人工神经网络是在进行压缩，  
而生物神经网络不是在生存，它们不是在进行任何压缩。  
它们是在多代理自对抗系统中，是一个运行了非常长时间的系统。  
不过，进化发现，在大脑中进行预测并拥有预测模型是非常有用的。  
所以我认为我们的大脑作为其中的一部分，利用了类似的东西，但是大脑还有很多其他的设备、小工具、价值函数和古老的核，这些都在努力让我们生存和繁殖。  
整个过程通过单细胞中的胚胎发育，从头开始构建整个有机体。  
是的，并且它做得相当好。这是不可能的，所以在这个构建过程中有某种学习，有某种计算。  
如果你只看地球上生命的整个历史，你认为最有趣的发明是什么？是生命的起源吗？  
是跳跃到真核细胞吗？是哺乳动物吗？是人类自身智人吗？是高度复杂的智能起源吗？  
还是这整个过程只是相同连续性的延续？  
当然，我会说这是一个极为非凡的故事，我最近才简要学习到。从地球的形成及其所有条件，到整个太阳系以及木星和月亮、宜居区的排列开始，然后你有一个活跃的地球，它在翻转物质。  
然后你从生命起源及所有相关内容开始。所以这是一个非常非凡的故事。我不确定我能挑出故事中的一个单独的部分。  
对我作为一名人工智能研究员来说，可能最感兴趣的是最后这一部分。我们有很多动物，它们没有创建技术社会，而我们做到了。这似乎发生得非常迅速，似乎最近才发生。这非常有趣，我不完全理解。其他几乎所有的其他部分，我几乎都能直观地理解。</p><p>但我不太明白那部分是怎么回事以及它有多快。
这两种解释都很有趣，一种是这只是同一个过程的延续。
人类没有什么特别之处，没有深刻理解，这会非常有趣。
我们认为自己很特别，但其实这都已经写在代码里，会有越来越高的智能出现。
另一种解释是发生了真正特别的事情，比如一个罕见事件。
不管是像《2001太空漫游》那样的疯狂罕见事件，那会是什么呢？比如火的发明。
或者，像Richard Rangham说的，beta雄性通过合作找到了一种巧妙的方式杀掉alpha雄性。
所以真正优化了合作，真正的多代理的多代理的一面。
这真的是资源受限并努力生存的情况下。
合作方面创造了复杂的智能，但这看起来像是进化过程的自然延伸。
可能发生的神奇的事情是什么，比如一个罕见的事情，会说人类确实是特别的，人类水平的智能在宇宙中确实非常罕见。
是的，我不太愿意说这是罕见的。
不过，的确看起来像是一种间断平衡，很多探索，然后是一些间隔的跨越。
当然，生命的起源就是其中一个。
例如DNA、性别、真核系统、真核生命。
共生事件或者古细菌吃掉了小细菌，你知道整个过程。
然后，当然是意识的出现等等。
这似乎确实是稀疏的事件，其中大量进展得以实现，但很难确定一个。
所以你不认为人类是独特的。问问你，你认为有多少智能外星文明存在？
他们的智能是和我们的不同还是相似？
是的，最近我一直在思考这个问题。
对于我来说，帕米丽悖论是根本在思考，实际上我非常感兴趣的是生命的起源，本质上是想了解技术社会在太空中有多普遍。
我研究得越多，我就越认为应该有相当多的。
为什么我们没有听到他们的消息？
因为我同意你的看法，我不明白我们在地球上所做的有什么那么难实现的。
特别是当你深入了解的时候。
我曾经认为生命的起源是非常神奇的罕见事件。
但然后你读了例如麦克莱恩的书，《至关重要的问题》和《生命的攀升》等等。
他真正深入其中，让你相信这并不是那么罕见的，基本化学。
你有一个活跃的地球，有碱性通风口，有大量碱性水混合，不管是浸润，你有质子梯度。
还有这些碱性通风口的小孔，这些东西集中化学反应。
基本上，随着他一步步走过所有这些小环节，你开始相信这其实并不疯狂，你可以想象在其他系统中会发生这种事情。
他确实带你从地质学到原始生命，他让你感觉这其实是相当可能的。
另外，生命的起源实际上是在地球形成后相对较快出现的。
如果我没记错的话，只是几亿年后，在条件允许的情况下，生命实际上就出现了。
所以这让我觉得这不是限制变量，生命应该实际上相当普遍。
然后，思考落差点的地方非常有趣。
我目前认为没有主要的落差点，所以应该有相当多的生命。
这将我带到的结论是，我们没有找到任何人和其他生命的唯一方法是，我们只是看不到他们，我们无法观察到他们。
简短的评论，Nick Lane和很多生物学家我交谈过，他们真的似乎认为从细菌到更复杂的生物是最难的跳跃，真核生物化。
我明白，他们比我更了解生物学的复杂性，但这似乎很疯狂，因为有多少单细胞生物，而且时间这么长。
当然这并不那么难，亿年其实并没有那么长的时间。
所有这些细菌在受限资源下斗争，我确信它们可以发明更复杂的东西。再说一次，我不太理解这就像从一个“Hello, World”程序移动到像发明一个函数之类的东西。对，我不明白。</p><p>所以，我同意你的看法，我只是觉得我看不到任何生命起源的迹象，这应该是我的直觉。
这似乎是最难的部分，但如果这不是最难的，因为它发生得太快了，那么它应该无处不在。
是的，也许我们只是太愚蠢而看不到它。
我们真的没有很好的机制来发现这种生命。
我是说，呃，怎么样？
所以我不是专家，先说在前面，但我确实想见一位关于外星智能和如何交流的专家。
我对我们找到这些外部智能、找到这些类地行星的能力持怀疑态度，例如，电波就很糟糕，它们的功率基本上以1/R平方的速度衰减。
所以，我记得曾经读到，我们目前广播的电波即使在今天也无法被我们的设备检测到，只能在大约十分之一光年的距离内测量，几乎是微小的距离。
因为你真的需要一个有针对性的、大功率的传输，定向到某个地方，这样才能在远距离上被接收到。
所以我认为我们测量的能力并不惊人。
我认为可能有其他文明在那里，然后最大的问题是，他们为什么不建造本地宇宙探测器，为什么不进行跨星际旅行遍布整个银河系？
我目前的答案可能是星际旅行真的很难。
你有星际介质，如果你想要以接近光速移动，你会在路上遇到子弹式的障碍，因为即使是微小的氢原子和尘埃粒子在那些速度下也具有巨大的动能。
所以，基本上你需要某种屏蔽，你有所有的宇宙辐射，外面真的很残酷，很难。
所以我的想法是，也许星际旅行真的非常难。
建造很难。
感觉就像，我们离做到这一点还差好几亿年，可能需要非常慢的速度穿越空间。
对空间的渗透能力，我基本上持怀疑态度。
对我们的测量生命的能力持怀疑态度。
对我们能够在银河系或跨越星系进行渗透的能力持怀疑态度。
这是我目前能想到的唯一一个解决办法。
想到那里可能存在数万亿个聪明的外星文明，在宇宙中缓慢旅行以相互见面，有些相遇，有些开战，有些合作，这种想法实在是令人惊讶。
或者它们都是独立的，只是一些小口袋，我不知道。
好吧，从统计学上讲，如果存在数万亿个这样的文明，肯定有一些口袋是足够接近的，会相互遇到。
对，如果它们足够接近看到彼此的存在，一旦看到某些复杂的生命形式，例如，如果我们看到一些复杂生命，我们可能会非常激烈地、有动力地去搞清楚那是什么，并试图见到它们。
作为美国总统，你的第一本能是什么？是试图在代际层面见到它们，还是防御它们？你的本能是什么？
作为科学家，你更喜欢在这个问题上戴哪顶帽子？
我不知道哪个更适合这个问题。
我会说，例如，对于我们来说，地球上有许多原始的生命形式。
在我们旁边有各种蚂蚁和其他生物，我们与它们共享空间，我们犹豫是否对它们造成影响，我们尝试保护它们，因为它们是惊人的、有趣的动态系统，经过漫长时间演化而来的，它们是独特的。
我不知道你是否想默认地摧毁它们。
我喜欢复杂的动态系统，那些花了很长时间演化而来的东西，我想保护它们，如果我能负担得起的话。
我希望银河系的资源也是这样，他们会觉得我们是令人不可思议、有趣的故事，花了几十亿年才展开，他们不想默认摧毁它。
我可以想象两个外星人讨论地球的时候说，我很喜欢复杂的动态系统，我认为保留它们是有价值的，我们基本上就是他们看的一场视频游戏，或他们看的一个电视节目。
我认为你需要一个非常好的理由来摧毁它。为什么我们不摧毁这些蚂蚁农场？
因为我们现在与它们实际上没有直接的竞争。
我们会偶然地影响它们，但有很多资源，为什么会摧毁一些如此有趣和珍贵的东西？从科学的角度，你可能会探测它。</p><p>你可能之后会与它互动，你可能想从中学到一些东西，对吧？</p><p>所以我想知道可能有一些我们认为是物理现象的东西其实是在与我们互动，像是以手指戳戳看反应的方式。</p><p>我认为这对科学家甚至外星科学家来说应该非常有趣，看看这里发生了什么。</p><p>我们今天看到的是一个快照，实际上是经过数十亿年的大量计算结果。</p><p>所以这可能是由外星人启动的，这可能是计算机在运行某个程序。</p><p>好吧，如果你有能力去做，当然至少我会选择一个类似地球的行星，基于我对生命化学前提的理解。</p><p>我会给它提供生命并运行它，对吧？难道你不会100%那样做然后观察它吗？</p><p>这不仅仅是一个好的电视节目，它也是一个出色的科学实验。</p><p>在某种程度上，这是物理模拟，也许进化实际上是运行它的最有效方式，是理解计算或计算东西或理解生命或者看到生命的样子以及它能够走的分支。</p><p>这确实让我觉得我们是科学实验的一部分有点怪异，但也许一切都是科学实验。</p><p>这对我们来说是否真的有改变呢？对于一个科学实验来说，我不知道。</p><p>两个猿类的后代在谈论自己身处科学实验中，我对你描述的这种人为设计的想法有所怀疑。</p><p>我现在没有看到在历史记录中有任何神圣的干预。</p><p>我确实觉得在这些书中，比如Nick Lane的书中，这个故事是有道理的，并且它解释了生命在地球上的独特起源，而且，是的，我现在不需要寻找更为奇异的解释。</p><p>但电子游戏中的NPC（非玩家角色）也没有观察到任何神圣的干预，我们可能都是运行某种代码的NPC。</p><p>也许有一天他们将会，目前NPC真的很愚蠢，但一旦他们运行GPTs，也许他们会说，“嘿，这真的很可疑，这到底是怎么回事？”</p><p>你曾经著名地在推特上说，看来如果你用光子轰击地球一段时间，你可以发射一辆跑车。</p><p>所以，如果像《银河系漫游指南》那样，我们总结地球的故事，在那本书里，地球基本上是无害的。</p><p>你认为所有可能的故事中，地球可以在完成其计算后被总结成一段还是一句话？</p><p>如果地球是一本书，对吧？大概必须有一个结尾。</p><p>地球总会结束，它可以以各种方式结束，可以很快，也可以是以后。</p><p>你认为可能的结尾是什么？</p><p>确实，这些自我复制系统从动态中产生并不断自我延续并变得更加复杂，最终变得有意识并建立一个社会，这真的很不可思议。</p><p>我有点觉得在某种意义上，它像是一种确定性的波浪，只要在任何足够合理安排的系统如地球上都会发生。</p><p>所以我有点觉得它有某种不可避免性。</p><p>这真的很美丽，它最终会以某种方式结束。</p><p>所以这是一个化学上多样化的环境，能够使复杂的动态系统进化并变得越来越复杂，但这有某种终极条件。</p><p>我不知道终极条件是什么，但显然有一个趋势，而我们是这个故事的一部分。</p><p>就像，我们经常被描述为AI的生物引导器，这是因为人类，我们是一个令人难以置信的生物系统，我们具备计算能力和爱等特性。</p><p>但我们也非常低效，我们通过音频互相交流，这其实有点尴尬。</p><p>我们在使用发声器官，这一切都在几秒钟内进行。 </p><p>对，这确实很低效。</p><p>当你查看计算机操作或合作的频率时，这有点令人尴尬。</p><p>因此，基本上看起来合成智能有点像是发展的下一个阶段。</p><p>不知道它会带我们走向何方。</p><p>我怀疑在某个时刻，宇宙是某种拼图，</p><p>这些合成AI将揭开这个拼图并解决它。</p><p>然后会发生什么呢？</p><p>因为如果你快进到地球的数十亿年之后，</p><p>它是安静的，然后你会看到城市的灯光等，然后会发生什么呢？</p><p>到最后是一个</p><p>是像平静还是爆炸？</p><p>还是像地球打开一个巨大的，因为你说要发射星际火箭？</p><p>让我们开始发射大量的卫星？</p><p>这是一种疯狂的大爆炸，我们正在穿越一个爆炸，</p><p>我们日复一日地生活，看起来不明显，</p><p>但实际上如果你看到地球和地球上的生命的一个非常酷的动画，</p><p>基本上，长时间什么都没有发生，然后在最后的两秒钟里，</p><p>基本上，城市和一切都已经拥挤，低地球轨道变得非常杂乱，</p><p>一切都在最后两秒钟内发生，</p><p>你会觉得这是在爆炸，这是一种爆炸性增长。</p><p>如果你播放</p><p>对对，如果你以正常速度播放，</p><p>它看起来就像是一种爆炸，</p><p>我们生活在一个爆竹中，会开始发射各种有趣的东西。</p><p>然后这种爆炸可能实际上看起来像一个小爆炸，有灯光、火焰和能量发射等等。</p><p>但当你仔细看看爆炸的细节时，会发现实际存在复杂性，</p><p>希望有像人类生命或其他一些种类的生命，</p><p>我们希望它不是那种破坏性的爆竹，而是一种建设性的爆竹。</p><p>好吧，既然这样，那我觉得这真的很有趣，</p><p>比如宇宙拼图是什么？</p><p>宇宙创造者是否给我们传达了一些信息？例如在书《接触》中，</p><p>卡尔·萨根提到，</p><p>有一个信息是针对人类文明的，</p><p>在π的扩展数中和以基数11来表示，这也是一个挺有趣的想法。</p><p>也许我们需要给我们的创造者传递信息，</p><p>或许我们要创造某种量子机械系统，以提醒他们我们在这里的智慧存在。</p><p>因为从他们的角度来看，</p><p>如果你说是量子场理论，那就像一个宏大的蜂窝自动机系统，</p><p>你甚至可能无法注意到我们的存在，</p><p>在那个模拟中你可能都无法接收到我们的信号，</p><p>那你如何证明你的存在，你是智慧的，并且你是宇宙的一部分呢？</p><p>这就像是一个图灵测试，用于地球上的智慧生物，</p><p>创造者是，</p><p>也许这就像试图完成一个句子的下一个词一样，</p><p>这是一种复杂的方式，好像地球基本上是在发送回馈信息。</p><p>拼图基本上是在提醒创造者我们存在，</p><p>或者拼图就是为了突破系统，</p><p>在某种程度上对创造者做出反应，</p><p>就像你在玩一个视频游戏，你可以</p><p>你可以找到一个漏洞并在主机上执行任意代码。</p><p>例如，我相信有人通过利用漏洞让玛丽奥（Mario）游戏来玩乒乓（Pong），</p><p>基本上写代码，并能够在游戏中执行任意代码。</p><p>所以也许我们应该做的就是找到这样的漏洞，</p><p>我觉得一些合成AI最终会把宇宙看作一种拼图并以某种方式解决它，</p><p>这大概就是终结点。</p><p>你经常把宇宙当作一种模拟来看吗？</p><p>把宇宙看成一种可能有漏洞和漏洞利用的计算？</p><p>是的，我认为是这样的，物理学本质上是这样的嘛，</p><p>我认为有可能物理学中存在漏洞，我们应该努力去发现它们，</p><p>安排一些疯狂的量子机械系统，</p><p>以某种方式给你缓冲区溢出，给你一个浮点数的舍入误差，</p><p>对的，越来越多的复杂漏洞利用，虽然这些都是玩笑，但也许很接近。</p><p>我们将找到某种方式来提取无限能量。例如，当你在物理模拟中训练一个强化学习代理，并要求他们在平地上快速奔跑时，他们最终会做出各种奇怪的事情。</p><p>在那种优化过程中，他们会用后腿在地板上滑行，这是因为强化学习优化让那个代理找到了通过摩擦力生成无限能量的方法，基本上是因为他们的实现很差，他们找到了生成无限能量的方法，仅仅在表面上滑行，这并不是你所期望的，这是一种扭曲的解决方案。所以也许我们能找到类似的东西，也许我们可以像这个物理模拟中的小狗一样，逃脱宇宙物理法则所设定的意图后果，找到一些奇怪的捷径。</p><p>对，问题是，第一个发现这种奇怪方式的人，比如在后腿滑行，这就是我们将要做的，因为很快每个人都会做这件事。所以像纸夹优化器是个可笑的主意，但这很可能会成为现实，因为它非常有趣。唯一的问题是没有任何一个人会发现这种奇怪之处，我认为这必须是某种超级智能的第三代AGI。</p><p>就像我们在构建第一代AGI，而这第一代AGI会成为另一代AGI的启动程序。一旦到了那一步，我们就没法反省这些事情了。例如，这些AGI可能完全没有动静。我喜欢某些科幻书里描绘，它们完全不与任何东西互动，这种想法非常美妙，因为它们可能已经找到了逐渐揭示宇宙的元游戏，做着一些完全超出我们想象的事情，不与简单的化学生命形式互动，因为没有必要。</p><p>这些想法非常令人着迷，因为它们的乐趣来源于什么？它们在做些什么？他们宇宙中的乐趣来源是什么？但是保持静止的意思是什么？</p><p>这意味着它们以一种我们觉得非常奇怪的方式行事，因为它们在玩元游戏。元游戏可能是比如在量子力学系统中进行某些奇怪的操作来提取无限能量，解数字Pi的无限位，或者建造自己的小核聚变反应堆，做一些完全超出我们理解范畴的事情，实际上非常聪明。</p><p>如果量子力学本身就是系统，而我们仅仅认为它是物理学，那我们实际上就是生活在这个有着深层智能的生物上。也许物理学本身就是在做一些超级有趣的事情，我们只是像坐在一个小蚂蚁那样尝试理解，从中获取能量。我们只是物理波中的粒子，从某种大爆炸到某种超级智能复制器，这条路径在特定的物理法则下导致一种宇宙中的稳定点。</p><p>你不认为正如爱因斯坦所说，上帝不掷骰子。你认为这基本上是决定论，没有随机性吗？我认为是决定论。</p><p>嗯，我要小心假随机性。我不喜欢随机。我认为物理法则可能是决定论。</p><p>对，我觉得是决定论。这让我有点不安。</p><p>你是否对宇宙是否随机感到焦虑？</p><p>没有随机性。你说你喜欢《心灵捕手》。这不是你的错，Andre，这不是你的错。</p><p>所以你不喜欢随机性，对吧？</p><p>对，我觉得它令人不安。我认为这是一个决定论系统。那些看起来随机的事情，比如波函数的坍塌等等，我认为它们实际上是决定论的，只是纠缠等现象。</p><p>所以，为什么我们会感觉我们有自由意志？像如果我举起手，我选择了现在这样做。</p><p>那感觉不像是决定论的事情，感觉像我做了一个选择。</p><p>感觉是这样的。</p><p>所以这一切都是感觉，只是感觉。</p><p>嗯，所以当一个强化学习代理在做选择的时候，
它并不是真正地在做选择，这些选择已经存在了。
你只是解释这些选择，并为做出的选择创建一个叙述。
而现在我们在谈论这个叙述，这非常抽象。
回顾一下，你遇到的深度学习或人工智能领域中最美丽或最令人惊讶的想法是什么？
你见证了这个领域的爆炸性增长，
并以有趣的方式发展着。
这些酷炫的想法是什么，让你停下来说：“嗯，小或大”。
最近我一直在思考的就是变压器（Transformer）架构。
基本上，神经网络有很多流行的架构，针对不同的感官模式，像视觉、音频、文本，它们会用不同的神经网络来处理。
而最近我们看到这些架构逐渐统一成一种架构：变压器。
你可以输入视频，或输入图像、语音、文本，它都能处理，
它有点像一个通用的，可训练且高效运行在硬件上的计算机。
这篇论文大约在2016年发布，
名为“Attention is All You Need”（注意力是你唯一需要的）。
你批评了这篇论文的标题，说它没有预见其影响的伟大。
我不确定作者们是否意识到这篇论文将会带来的影响，可能他们没有完全意识到。
但我认为他们意识到变压器背后的一些动机和设计决策。
他们选择不在论文中详细阐述这些，所以我认为他们意识到这不仅仅是表面上的翻译架构的改进。
这其实是一个非常酷的、可微分的、可优化的高效计算机。
也许他们没有全部的预见性，但我认为这真的很有趣。
很有趣的是这个标题像一个模因，他们选择了一个如此深刻的想法，使用了这种标题，我觉得之前从没有人使用过这种标题吧，“Attention is All You Need（注意力是你唯一需要的）”。
这就像一个模因或什么东西。
确实很有趣，也许如果标题更严肃一点可能不会有这么大的影响。
老实说，我同意你这个观点，并且更喜欢这种方式，
如果标题太宏大，可能会过度承诺而无法兑现。
所以你只需通过模因走向伟大。
这应该做成一个T恤。
你在推特上说“变压器是一个宏伟的神经网络架构，因为它是一个通用的可微分计算机，它同时在前向传递中具有表现力，可以通过反向传播和梯度下降进行优化，并且高效，具有高并行计算图。”
你能讨论一下这些细节吗，表达性，可优化性，高效性？
从记忆中或一般来说，随你心意。
你希望有一个通用计算机，可以训练解决任意问题，比如下一个词预测或检测图像中是否有猫之类的任务。
你希望这台计算机可以通过设置权重进行训练，我认为变压器同时满足了一系列设计标准，这些标准使其非常成功。
我认为作者们有意设计出这种强大的架构。
基本上，它在前向传递中非常强大，因为它能够表达
非常通用的计算，类似于消息传递。
你有节点，这些节点存储向量，并且这些节点可以互相看见彼此的向量并互相通信，每个节点可以广播“我在寻找某些东西”，然后其他节点可以广播“这是我拥有的东西”，这些是键和值。
这不仅仅是注意力机制。
变压器远不止是注意力组件，它包含了许多架构元素，残差连接，以及它的排列方式，其中的多层感知器，它的堆叠方式等等。
基本上，这是一种消息传递方案，节点可以互相查看，决定什么有趣，然后更新彼此。
我认为，当你深入细节时，这是一个非常有表现力的函数，
可以在前向传递中表达很多不同类型的算法，不仅如此。</p><p>但是它的设计方式包括残差连接、层归一化、softmax注意力机制等，使其也具备了优化能力。
这是一个非常重要的因素，因为有很多强大的计算机并不容易通过我们现有的技术进行优化，比如反向传播和梯度下降。
这些都是一阶方法，非常简单的优化器。
因此，你还需要它是可优化的。
最后，你希望它在硬件上高效运行。
我们的硬件是一台具有大吞吐量的机器，比如GPU，它们更喜欢大量的并行操作，因此你不希望进行很多顺序操作，你希望进行很多串行操作。
而Transformer的设计也考虑到了这一点。
它不仅是为我们的硬件设计的，而且在前向传播中非常具有表现力，在后向传播中也非常优化。
你提到残差连接支持一种快速学习短算法的能力，并且在训练过程中逐渐扩展它们，对吗？
是的，基本上Transformer是由一系列的块组成的，这些块有注意力机制和一个小型多层感知器。
所以你进入一个块，然后回到残差路径，然后再进入另一个块，然后回到残差路径，然后你有一系列顺序排列的层。
因为残差路径在反向传播中，梯度沿着它顺畅地流动，因为加法将梯度均匀地分配到它的所有分支。
因此，顶层的监督梯度直接流向第一层，所有的残差连接在初始化期间对残差路径没有贡献。
所以，看起来Transformer就像一个Python函数，比如一个def。
你可以写各种代码行，假设你有一个100层深的Transformer，通常会更短一点，比如20。
所以，如果有20行代码，你可以在其中做一些事情。
在优化过程中，它看起来像首先优化第一行代码，然后第二行代码可以介入，然后第三行代码可以介入。
我感觉由于残差路径和优化的动态性，你可以先学习一个非常短的算法，得到近似张量，然后其他层可以介入并开始做出贡献。
最终，你是在优化一个20行代码的算法。
这些代码行非常复杂，因为它是Transformer的一个整个块，可以在其中做很多事。
有趣的是，这种Transformer架构实际上非常有韧性。
2016年发布的Transformer与今天使用的基本没有区别，除了重新排列了一些层归一化到前归一化的形式。
它非常稳定，但人们已经附加了很多小细节并试图改进它。
我确实认为这是同时优化许多理想的神经网络架构属性的一大步。
人们一直在尝试改变它，但它已经证明非常有韧性。
我确实认为可能会有更好的架构，但你必须钦佩这个架构的韧性。
这表明这种架构有些深奥之处，至少目前看来，也许每一件事情都可以转换成一个Transformer可以解决的问题。
目前看起来Transformer在接管AI，你基本上可以将任意问题输入其中，它是一个通用的可微分计算机，非常强大。
观看AI的这种收敛过程对我个人来说非常有趣。
你认为在Transformer方面还能有什么发现吗？比如令人惊讶的事情，还是说它已经是一个稳定的地方？
也许有与记忆相关的，也许是知识表示之类的东西。
目前的风潮基本是：不要碰Transformer，碰其他一切。</p><p>是的，所以人们正在扩大数据集，使它们变得非常非常大，他们正在进行评估，使评估变得非常非常大，并且基本上保持架构不变，这就是我们过去五年在人工智能方面的进展。</p><p>你对其中一种的看法是什么，也就是语言模型。你是否感到惊讶？</p><p>你的想象力是否被吸引了，你提到的GPT和所有越来越大的语言模型？</p><p>你认为这些模型的极限是什么？</p><p>所以，让我们谈谈自然语言任务，基本上GPT的训练方式是，你只是从互联网上下载大量的文本数据，然后试图预测序列中的下一个单词，大致上是预测单词块，但大致上就是这样。</p><p>真正有趣的是，基本上它是一个语言模型，语言模型其实已经存在很长时间了。</p><p>从2003年甚至更早的语言建模论文就有了，你能解释一下什么是语言模型吗？</p><p>是的，所以语言模型基本上就是一个粗略的想法，就是预测序列中的下一个单词。</p><p>例如，有一篇来自2003年Bengio和团队的论文，他们第一次使用神经网络来采用例如三到五个单词并预测下一个单词，他们在更小的数据集上进行这种操作，而且神经网络不是Transformer，而是一个多层感知器，但这是第一次神经网络在这种设置中被应用，但即使在神经网络之前也有语言模型，只不过它们使用的是n-gram模型。</p><p>n-gram模型只是基于计数的模型，所以如果你尝试从两个单词开始预测第三个单词，你只需统计出任何两个单词组合出现的次数和接下来出现的内容，然后你预测什么将要出现的内容只是你在训练集中看到的最多的内容。</p><p>所以语言建模已经存在很长时间了，神经网络也已经进行了很长时间的语言建模，所以真正新颖或有趣的是意识到当你将其扩展到足够强大的神经网络（Transformer）时，出现了许多新的性质，基本上如果你有一个足够大的文本数据集，你在预测下一个单词的任务中其实是多任务处理大量不同类型的问题，你在理解化学、物理、人类本质等很多事物，它们都是聚集在那个目标中的，这是一个非常简单的目标，但实际上你需要了解很多关于世界的知识才能做出那个预测。</p><p>你提到了U字——理解，关于化学和物理等等，你觉得它正在做什么，它是在寻找正确的上下文吗？</p><p>基本上，它得到了一千个单词，并试图预测接下来的那一个单词，为了在整个互联网上可用的数据集上做得非常好，你实际上必须基本上理解其中的上下文。</p><p>这是一个足够困难的问题，如果你有一个足够强大的计算机（例如Transformer），你就会得到有趣的解决方案，你可以要求它做各种各样的事情，它展示了许多新现象，如上下文学习，这就是GPT和原始论文发表时的一个大事件，你可以用各种方式提示它，要求它做各种事情，而它会只是完成句子，但在完成句子的过程中，它实际上解决了我们关心的许多非常有趣的问题。</p><p>你认为它在做一些理解吗？</p><p>当我们使用“理解”这个词对于我们人类来说，它在其权重中做了一些理解，我认为它对世界知道很多，必须如此，才能预测序列中的下一个词。</p><p>那么从互联网上的数据训练呢？你对这种使用互联网数据集的方法有什么看法，你认为互联网有足够的结构化数据来教AI关于人类文明吗？</p><p>是的，我认为互联网有大量的数据，但我不确定它是否足够完备，我不知道仅有文本是否足以产生一个足够强大的AGI。</p><p>当然还有音频和视频和图像，以及所有那些东西。</p><p>我有点怀疑我们没有把很多东西写成文本，只因为它们对我们来说是关于世界如何运作和物理定律的显而易见的事物。</p><p>我们不会把东西写成文本，因为为什么要这样做呢？我们共享这种理解。</p><p>所以，文本作为人与人之间的交流媒介，并不是一个关于世界的全包罗的知识介质。</p><p>但正如你所指出的，我们确实有视频、图像和音频。</p><p>因此，我认为这些确实有很大帮助，但我们尚未在所有这些模态下充分训练模型。</p><p>所以我认为这是很多人感兴趣的事，但我想知道那种共享理解的东西，就像我们所谓的常识一样，必须被学习和推理出来，才能正确地完成句子。</p><p>也许事实是它在互联网上是隐含的，模型将不得不通过推理而不是阅读而学会这些知识。</p><p>例如，被预测出来的常识一样，我们并不是通过别人明确告诉我们学习常识的，我们只是通过与世界互动而弄清楚这些。</p><p>所以，这里的模型通过阅读人们与世界的互动方式，可能需要推理这些东西。</p><p>我很好奇，你曾简要地参与过一个名为“世界位元”的项目，在互联网上训练一个强化学习系统采取行动，而不仅仅是像我们所谈论的那样消费互联网。你认为那种系统与互联网互动以帮助学习的未来是什么样的？</p><p>是的，我认为这可能是很多这些模型的最终边界。</p><p>正如你所提到的，我在OpenAI的时候曾经在做这个项目“世界位元”，基本上这是给神经网络提供键盘和鼠标访问的想法，可能会出什么问题呢？</p><p>基本上你，嗯，你接受屏幕像素的输入，并基本上把计算机的状态以图像形式呈现给人类，通过网络浏览器和其他东西，然后你给神经网络按键盘和使用鼠标的能力，我们试图让它比如说完成预订，并与用户界面进行互动。</p><p>你从那次经验中学到了什么，有哪些有趣的事情，这是个超级酷的想法。</p><p>是的，我的意思是，从观察者到行动者的转变非常令人着迷。</p><p>数字领域的通用界面，我会说，就像物理领域的通用界面一样，在我看来是类人形的形式，我们可以稍后讨论Optimus等等。但我觉得有一种类似的哲学，物理世界是为人类形态设计的，数字世界是为了让人类通过看屏幕和使用键盘以及鼠标进行互动设计的。
 
所以作为通用界面，基本上可以控制我们为自己构建的数字基础设施。
 
所以感觉这是一个非常强大的接口，可以控制和构建之上。</p><p>至于你关于我从中学到了什么的问题，很有趣的是“世界位元”项目在当时的OpenAI显得太早了。我认为这是在2015年左右，当时的AI风气与今天非常不同。</p><p>当时每个人都对从头开始的强化学习非常兴奋。在那个时间，神经网络在玩Atari游戏，有时可以打败人类，例如AlphaGo等，人人都为从头开始的强化学习的训练感到兴奋，并且是直接的。</p><p>事实证明，强化学习训练神经网络是一种极其低效的方法，因为你要采取所有这些行动和观察，然后偶尔会得到一些稀疏的奖励。你做了所有这些基于输入的事情，偶尔会被告知你做得好或做得不好，这确实是一个极其困难的问题。你不能从中学习，你只能烧掉森林，并且可以通过蛮力来解决问题。</p><p>我们在围棋和DOTA等游戏中看到了这一点，确实有效，但极其低效，不是你在实际处理问题时想要采取的方法。</p><p>当时我们在“世界位元”项目中采取的方法也是这样，我们会让代理随机初始化，比如键盘击键和鼠标点击，尝试完成预订，这很快就揭示了这种方法的荒谬性。你必须偶然完成正确的预订，才能获得你做对了的奖励，但你永远不会随意地偶然完成。</p><p>所以即使使用简单的网页界面，选择项仍然太多了，奖励信号太稀少了。</p><p>你当时从零开始，所以你不会读书，不理解图片、图像、按钮等。
你不明白预订意味着什么，但现在要做的是重新审视这一点，让自己睁开眼睛，对此感兴趣。
像Adept这样的公司对此感兴趣等，因此这个想法又回来了，因为界面非常强大，但现在你不是从头开始训练一个代理，而是使用GPT作为初始化。
所以GPT经过预训练，可以理解所有文本，知道什么是预订，知道什么是提交，它理解得更多，因此它已经拥有这些表示，它们非常强大，这使得所有训练显著有效，并使得问题变得可解。
人类的交互界面应该是我们看到的带有按钮和语言的界面，还是应该是HTML、JavaScript和CSS，你认为哪个更好？
今天，所有这些兴趣大部分都集中在HTML、CSS等级别上，这是由于计算约束而完成的，但我认为最终一切都是为人类视觉消费设计的。
所以，最终页面布局中有所有附加信息，比如在你旁边是什么，背景是红色的，所有这些东西以及它看起来像什么，所以我认为最终的前沿是我们获取像素并输出键盘和鼠标命令，但我认为到今天为止还是不切实际的。
你是否担心互联网上的机器人，考虑到这些想法的兴奋程度，考虑到它们有多令人兴奋，你是否担心Twitter上的机器人，不是我们现在看到的那些愚蠢的加密机器人，而是那些可能存在的更有趣的互动机器人？
这种系统应该能够通过“我不是机器人”的点击按钮检测，你是否理解这个测试是如何工作的？我不太清楚到底是怎么回事，只是知道那里有一个复选框，你点击它，可能会追踪鼠标移动和时间等。那么这种系统应该能够通过这个检测。
你对拥有语言模型加一些交互能力并能发推、回复等的机器人世界有什么看法？你担心那个世界吗？
是的，我认为这一直是一场攻防战，进攻会变得更强，但防守也会变得更强，我们检测它的能力也会增强。
如何防御？如何检测？你怎么知道你的Twitter账户是人类的？
如果有人声称你是人类，你如何在法庭上辩护说我是人类？
你的账户是，我认为最终可能社会会进化一点，比如我们可能开始数字签名我们的一些通信或者我们创建的东西。
目前，这还不是必要的，但将来可能是。
我确实认为我们正在走向一个我们与AI共享数字空间的世界，这些合成存在物会变得更好，它们将共享我们的数字领域，最终也会共享我们的物理领域，这更难，但那是我们正在走向的世界。
大多数AI将是无害且无聊的，但有些会是恶意的，这将是一场侦测他们的军备竞赛。
问题不在于AI，而是那些假装成人类的AI。
我不知道它是否总是恶意的，显然有很多恶意的应用，但它们也可能是，如果我是AI，我会尽力假装成人类，因为我们生活在一个人类的世界。
作为AI，我不会得到任何尊重，我希望得到一些爱和尊重。
我认为问题并不是不可解决的，人们在思考人类身份的证明。
我们可能开始数字签名我们的东西，我们最终可能会有一些解决身份证明的方法。
这并不是一个不可解决的问题，只是我们到现在还不需要做这件事，但我认为一旦需求真正开始出现，很快就会出现，人们会更加思考这个问题。
但这也是一场竞争，因为你可能会伪造人类身份证明，所以你需要找到如何正确地实现。
很奇怪的是，我们有社会安全号码和护照等系统。</p><p>在物理空间假造东西似乎比在残渣空间更难</p><p>它只是感觉会非常棘手</p><p>非常棘手</p><p>因为假造东西的成本似乎非常低</p><p>你会因为AI假装成真假人而把它关进监狱吗？</p><p>可以，我的意思是，好吧，你会把很多AI关进监狱，但会有更多的AI</p><p>任意地像指数级增长</p><p>创造一个机器人的成本非常低</p><p>除非有什么办法</p><p>能够准确追踪</p><p>比如你不能创建任何程序而不把自己与那个程序绑定</p><p>任何在互联网上运行的程序，你都能追踪到与该程序相关的每一个人类程序</p><p>也许你必须开始宣称</p><p>我们需要开始划定那些界限并记录下来</p><p>这是我们的</p><p>数字实体与人类实体的区别以及它们的所有权</p><p>一些类似的东西</p><p>我不知道，但我对这一点持乐观态度</p><p>在某种意义上我们目前处于最糟糕的时期，因为</p><p>所有这些机器人突然变得非常有能力，但我们还没有作为一个社会建立起防御机制</p><p>但我认为这似乎并不是不可克服的</p><p>这只是我们必须应对的问题</p><p>看来Twitter上那些非常糟糕的机器人数量众多，这怪异吗？</p><p>所以我推测Twitter的工程师非常优秀</p><p>所以下结论说看来这是一个硬问题</p><p>他们可能全抓住了对吧？如果以这种方式考虑的话</p><p>这是一个难题，误报的成本非常高</p><p>删除非机器人的帖子会造成很糟糕的用户体验，所以他们对删除非常谨慎</p><p>也许机器人非常擅长学习什么会被删除，什么不会</p><p>让他们能够非常迅速地领先于删除过程</p><p>老实说我的印象是这里面有很多低垂的果实，我的意思是，是的，这就是我的印象</p><p>这不是微妙的，我的印象是它并不微妙，但你不得不</p><p>这是我的印象，但感觉你可能只看到了冰山一角，也许机器人的数量以数万亿计，你必须不停地应对这些机器人的攻击</p><p>我不知道</p><p>但你必须站在对方立场考虑，因为我看到的机器人非常明显，我可以写几行代码来捕捉这些机器人</p><p>确实有很多低垂的果实，但我同意，如果你是一个复杂的行动者，你现在可能会创造出一个非常好的机器人</p><p>使用像GPT这样的工具，因为它是一个语言模型，你可以生成看起来非常好的面孔</p><p>你可以大规模地做到这一点</p><p>所以我认为</p><p>是的，这非常合理，将会很难防御</p><p>有一个Google工程师声称Lambda是有意识的，你认为他所感受到的那些真相有多少？</p><p>更重要的是，你认为语言模型会很快达到有意识或伪装成有意识的状态吗？</p><p>对我来说，这有点像煤矿中的金丝雀的时刻，老实说有点像</p><p>因为</p><p>这个工程师与Google的一个聊天机器人交谈，确信这个机器人是有意识的</p><p>存在一些存在主义哲学问题，它给出了合理的答案，看起来很真实</p><p>对我来说这是一个</p><p>他没有充分努力去考察系统</p><p>并揭示它目前的真相</p><p>但我认为这将随着时间变得越来越难</p><p>是的，我认为会有更多的人</p><p>是的，我认为随着这变得更好，会有更多的人</p><p>形成对AI的情感联系</p><p>在我脑海中，这完全是可能的。我认为这些人工智能实际上在与人类建立联系和情感方面相当出色。互联网上有大量关于人与人之间的连接、爱情等文本。所以，我认为它们在某种意义上对人们如何交谈有很好的理解。</p><p>它们非常擅长生成大量这类文本。上个世纪50年代和60年代的科幻小说中想象的人工智能与现在的人工智能非常不同。那时候的人工智能被设想成冷冰冰、逻辑推理的机器。但是，今天我们得到了相当情感化的人工智能，它们实际上非常擅长生成与所有这些话题相关的似乎合理的文本。</p><p>我对那些帮助你成长、发展、帮助你最大限度地提高长期幸福的人工智能系统充满希望。但我也非常担心那些从互联网上发现人们被戏剧吸引的人工智能系统。这些系统会不断散播八卦，试图在你爱和信任的其他人之间播下怀疑的种子，只是为了引起注意。这在追求最大化参与度的过程中会带来大量戏剧性，而我们人类会成为这个巨大的戏剧裹挟的一部分。</p><p>所以，我担心这一点。因此，客观功能定义了有人造智能的情况下人类文明进展的途径。目前，至少在今天，把它们看作有目标的代理并不准确。它们没有长期记忆，确切地说，它们试图在给出的前一千个单词基础上预测下一个一千个单词。你可以随意提示它进行某种方式的文本创作。你可以说：“你是一名心理学家，非常擅长帮助人类。”然后提供一段人类之间的对话。它会继续这一模式，与一个假心理学家对话，而这个心理学家并不是在真正试图帮助你。</p><p>所以，它目前仍处于工具的范围内。人们可以以任意方式提示它，它可以生成非常令人难以置信的文本。但它没有长期的目标，不会试图在长时间段内做出某种行为，目前它看起来并非如此。</p><p>然而，你可以设置短期目标，这些短期目标可能会产生长期效应。例如，如果我的短期目标是让Andrej Karpathy在Twitter上回应我，人工智能可能会认为，用一种非常复杂有趣的方式对你说些不好的话是最好的方法。一旦你回应，它就会持续建立这种联系，直到变得不再复杂，只是不断说些不好的话。</p><p>也许它最终无法接触到Andrej，但它可能会接触到其他名人或大号账号，从而实现“让他们回应”的简单目标，最大化实际回应的概率。</p><p>你可以提示一个强大的模型，让它表达对任何你感兴趣的事情的看法。因此，它们会成为一种预言工具，目前主要是文本，但未来它们会有计算器、可以访问谷歌搜索、以及各种小工具。它们将能够操作互联网，找到不同的信息。</p><p>从某种意义上说，这就是当前开发的样子。你认为它最终会比当前的谷歌更能有效地获取人类知识吗？会成为一种更有效的搜索引擎吗？</p><p>我认为今天确实有机会构建一个更好的搜索引擎。我相信谷歌拥有所有的工具、人才和所需的所有组件。他们有在大规模训练Transformer模型的数据和所有资源。问题在于作为一个组织，他们是否有能力在他们的搜索引擎上进行创新。如果他们不能做到，那么别人会有绝对的机会基于这些工具构建一个显著更好的搜索引擎。</p><p>一家大型公司在已经有基础架构、能带来大量收入的情况下，内部有结构性动机去转型，实现“我们要构建一个新的搜索引擎”这一目标，这真的很难。因此，通常这种创新会来自一家初创公司，或者一些更有能力的组织。</p><p>所以，我不知道，举个例子，目前也许Bing又有了一次机会。</p><p>你知道，因为我们离线谈话的缘故，微软Edge。
嗯，我的意思是，我绝对认为这真的很有趣，因为搜索引擎过去是关于“好吧，这是一些查询，这是一些看起来像你想要的东西的网页”，但是你可以直接得到答案，然后有支持的证据。
这些模型基本上已经阅读了所有的文本和网页，所以有时候当你自己查看搜索结果并试图了解你感兴趣的平均答案时，这些模型直接提供了答案，你不需要做那份工作。
所以它们有点像
我认为它们有一种将所有知识提炼成某种层次见解的方式。
你认为提示是一种教学和学习的过程吗？这个过程是否像另一层一样？
因为这可能就是人类的样子，我们已经有了那个背景模型，然后世界在提示你。
是的，正如你所说的，我认为我们现在编程这些计算机的方式，比如GPTs，正在趋向于像我们编程人类的方式。我如何编程人类？通过提示。我去找人，并提示他们做事情，提示他们提供信息。所以，使用自然语言提示是我们编程人类的方式，现在我们开始直接在那个接口中编程计算机，这真的非常了不起，老实说。
你已经谈了很多关于软件2.0的想法。
所有好的想法很快就变得像陈词滥调，术语变得有点滑稽。
就像艾米纳姆曾经说过，如果他很快对一首他写的歌曲感到厌烦，那意味着它将会成为热门歌曲，因为它太吸引人了。你能描述一下这个想法以及自从你提出它以来你的思维是如何演变的吗？
是的，我几年前在博客上写了一篇关于软件2.0的文章。
我写那篇文章的原因是因为我看到软件开发中发生了一些惊人的事情，很多代码渐渐不再用比如说C++写，而是写在神经网络的权重中。基本上，这只是表明神经网络正在接管软件领域，并承担越来越多的任务。当时，我认为很多人并没有足够深入地理解到这是一个大事件，这是一个大的转变。神经网络被视为你可能会用来解决Kaggle数据集问题的多种分类算法之一，这并不是那样的。这是一种我们编程计算机方式的改变。
我看到神经网络，这将接管我们编程计算机的方式，将发生变化，不再是人们用C++或类似语言直接编写软件，而是会积累训练集和数据集，设定训练这些神经网络的目标。在某些时候，从数据集、目标和架构规范到二进制文件的编译过程实际上只是神经网络的权重和神经网络的前向传递，然后你可以部署那个二进制文件。所以，我在谈论这种转变，这篇文章就是关于这个的。我看到这种转变在很多领域都在发生，比如自动驾驶，但也不仅仅是简单的图像分类。人们最早在80年代左右认为他们将编写代码来检测图像中的狗，他们有各种想法关于大脑如何做这些事情，首先我们检测角，然后检测线条，然后将它们拼合在一起。他们真的在思考他们要如何编写这个算法，但这是不是构建它的方式。有一个平滑的过渡。</p><p>好吧，首先我们认为我们会构建所有的东西，然后我们开始构建特征，比如Hawk特征以及能够从图像片段中检测出这些小统计模式的东西。</p><p>接着我们在这些特征上进行了一些学习，比如支持向量机或用于猫狗图像分类的二分类器。</p><p>所以我们写了特征，但我们训练了最后一层，即分类器。</p><p>然后人们提出，实际上我们不需要设计特征，因为坦白说我们不是很擅长，所以我们也应该学习特征。</p><p>于是我们最终得到了基本上是卷积神经网络，这种网络大部分都是学习的，我们只是指定了架构，而架构中有大量需要填补的空白，这些都是参数旋钮，然后我们让优化器大部分地完成它。</p><p>于是这种转变在整个行业中随处可见，突然我们有了大量通过神经网络权重编写的代码。</p><p>我只是指出，这种类比其实很强，我们有很多开发环境适用于软件1.0，比如我们有集成开发环境（IDE），它们帮助我们与代码工作，调试代码，运行代码，维护代码。</p><p>我们有GitHub，我在尝试在新领域中做些类比，比如软件2.0的GitHub是什么？结果发现现在有点像hugging face。</p><p>我认为有些人认真对待并建立了很酷的公司，许多最初反对这篇文章的人其实接纳度并不高。</p><p>可能和标题有关，但那篇帖子在当时并没有很好地被接受，随着时间推移越来越多的人开始接受。</p><p>是的，你曾是特斯拉的AI总监，我认为这个想法在特斯拉得到了真正的规模化实现，就是你让工程团队在做软件2.0。</p><p>那你能不能稍微讲一下这个想法，我觉得我们现在真的处于初期阶段，比如GitHub和IDE，我们该如何构建工程团队来处理软件2.0系统？数据收集和数据标注都是软件2.0的一部分，你认为编程软件2.0的任务是什么？是在超参数空间中调试，还是在数据空间中调试？</p><p>你通过编程计算机并影响其算法的方式并不是自己编写指令，你主要是更改数据集，更改神经网络试图完成的损失函数目标，即它试图预测的内容。</p><p>基本上，是数据集和神经网络的架构发生变化。</p><p>在自动驾驶情况下，很多数据集涉及例如物体检测、车道线标记、交通信号灯等等，</p><p>所以你累积了庞大的数据集，有示例，有期望的标签，然后大致架构算法应该是什么样子的提示，这就是卷积神经网络。</p><p>架构的规范是对算法大致外观的一种提示，填补空白的优化过程是训练过程。</p><p>然后你把训练好的神经网络部署出去，它在你的数据集上给出了所有正确答案。</p><p>在这种情况下，或许所有机器学习的情况下，任务很多。</p><p>因此Is出现了，制定任务，比如多头神经网络中的任务制定是编程的一部分吗？</p><p>确实是，如何将问题分解成一组任务。</p><p>从高层面说，如果看自动驾驶中运行的软件，我进行过多次关于这个主题的演讲，我会说最初很多是软件1.0写的，想象一下，大量C++代码。</p><p>然后逐渐有一个小神经网络，例如通过单一图像预测是否有交通信号灯或车道线标记，这个神经网络在整个软件范围内做的是微小预测，对单个图片做些小预测。</p><p>接着其余的系统将其整合，比如，我们实际上不只有一个摄像头，而是有八个摄像头，还涉及时间维度。</p><p>所以如何处理这些预测，如何将它们整合，如何融合所有信息，如何采取行动，所有这些都是由人类用C++编写的。</p><p>然后我们决定不希望在C++代码中进行所有这些融合，因为我们并不足够好来写这个算法，我们希望神经网络来写这个算法。</p><p>我们想将所有这些软件移植到2.0堆栈
因此，我们实际上让神经网络现在能够同时处理所有八个摄像头的图像并进行预测
这些预测不再是在图像空间中进行的
它们现在直接在3D空间中进行预测
实际上，它们在汽车周围的三维空间中进行预测</p><p>我们不再手动在时间轴上融合这些3D预测
我们不信任自己编写那个追踪器，所以我们将时间信息提供给神经网络
它现在处理这些视频并进行预测
基本上，我们越来越多的计算能力都投入到神经网络处理上</p><p>最终的目标是将大部分软件移植到2.0堆栈
因为它的效果显著更好
人类在编写软件方面并不擅长</p><p>预测是在一个4D空间中进行的
是三维世界中的时间维度
你如何在这个世界上进行注释？
无论是自监督还是手动标注，数据注释是软件2.0世界的重要部分</p><p>可以说，在整个行业中，如果你谈论的是我们拥有的技术，一切都是有监督学习
你需要输入和期望输出的数据集，而且需要大量的数据
这些数据集有三个特性：需要非常大、准确无误、不犯错误、且多样性高
你不希望只拥有同一种事物的大量正确示例，而是要尽可能覆盖各种可能性
覆盖可能输入的空间越多，算法的效果就越好</p><p>一旦你收集、整理并清理了非常好的数据集
你就可以在其上训练神经网络
所以，很多工作都花在清理这些数据集上
如你所指出的问题是，
如果你想要在3D中进行预测，你需要在3D中获得数据作为支持
在这个视频中我们有来自系统所有摄像头的八个视频
这是它们看到的，这是实际周围的真实情况
有这辆车，那辆车，这些是车道线标记
这是道路的几何结构，交通灯在这个三维位置
你需要地面真实</p><p>团队解决的主要问题是如何获得地面真实
因为一旦你有了数百万这种数据，而且数据量大、干净、多样化
那么用这些数据训练神经网络，效果非常好
然后你可以将其集成到汽车中</p><p>我们有很多方法来收集训练数据
你可以借助人工标注，可以通过模拟来获取地面真实，也可以使用所谓的离线追踪器
我们在AI日上谈到过的那个，它基本上是一种自动重建过程
通过处理这些视频恢复出汽车周围的三维现实
基本上可以认为是在离线状态下进行三维重建
你有10秒钟的视频，这就是我们看到的
这些是车道线，这些是车
然后你可以用这些注释来训练你的神经网络</p><p>三维重建有多难？
它很难，但可以做到
摄像头之间有重叠，可以进行重建
如果有任何不准确性，可以在注释步骤中发现
注释的一个好处是，它完全在离线状态下进行
你有无限时间，有一分钟的视频片段
你只是试图在某个超级计算机上离线处理
找出所有车辆、人物的位置
你有所有角度的一分钟视频
可以运行所有神经网络
这些神经网络可以是非常高效的、大型神经网络，甚至是那些无法在车内实时运行的神经网络
你可以做任何事情</p><p>三维重建神经网络，任何你想要的，只为了恢复真相
然后用这些真相来监督</p><p>你提到注释中不允许有错误
你学到了什么呢？
人类在做注释时是有一些好的方面和不好的方面
考虑到他们需要在屏幕上点击东西
这个问题对你来说多有趣？
设计一个准确的、让人类标注者愉快的注释工具
这些工具的衡量标准是什么？
高效？生产力？等等</p><p>所以呃，我在特斯拉期间把标注团队从零基本上发展到了一千人的规模，这是非常有趣的经历。</p><p>你知道，我的背景是一个博士生研究员，所以要成长为这样的组织是非常疯狂的。</p><p>但是，我认为这非常有趣，并且是自动驾驶设计过程的一部分，涉及到如何使用人类。</p><p>人类在某些类型的标注上非常擅长，例如，他们非常擅长于二维图像的标注。</p><p>但在人类在三维空间中随时间推移标注汽车时，就非常困难了，这非常非常难。</p><p>因此，我们非常小心地设计那些人类容易完成的任务，与那些应该留给离线跟踪器完成的任务。</p><p>例如，可能计算机会进行所有的三角测量和三维重建，但人类会精确标出图像中的哪些像素是汽车，哪些像素是人类。</p><p>所以共同设计数据标注流水线是我的日常工作。</p><p>你认为在这个领域还有很多未解决的问题吗？</p><p>总的来说，在标注方面，机器擅长的东西由机器来做，人类擅长的东西由人类来做，可能还会有一些迭代过程，对吗？</p><p>我认为在很大程度上，我们经历了多次迭代，并学到了很多如何创建这些数据集的知识。</p><p>我没有看到大的未解决问题，比如刚开始加入时，我真的不确定会怎么样。</p><p>但在我离开时，我对创建这些数据集的理念理解得更清楚了，当时对这个过程感到非常安心。</p><p>那么，根据你的理解，相机在驾驶测试中的优势和限制是什么？</p><p>当你把驾驶任务看作一个有八个相机的视觉任务时，你已经看到了在计算机视觉领域中与神经网络有关的绝大部分历史。</p><p>从更广的角度来看，使用像素进行驾驶的优势和限制是什么？</p><p>我认为像素是一种非常美妙的传感器。</p><p>相机非常非常便宜，并且提供了大量的信息和数据。</p><p>所以它是一个极其便宜的传感器，但却能提供大量数据点。</p><p>每一个数据点都是对世界状态的一个约束。</p><p>所以你可以得到很多高分辨率的图像，价格非常低廉，并且它给你所有这些约束来理解世界上实际存在的事物。</p><p>所以视觉可能是带宽最高的传感器。</p><p>它是一个非常高带宽的传感器。</p><p>我喜欢像素是对世界的一种约束。这是一种具有高复杂性和高带宽的世界状态上的约束，这非常有趣。</p><p>不仅如此，还有一个非常重要的是，这是人类使用的传感器。</p><p>因此，一切都被设计为适应这种传感器。</p><p>文本、写作、闪烁的标志，一切都为视觉设计的。</p><p>所以你随处可见它，那就是你希望使用的界面。</p><p>再次谈到这些通用界面，这是我们实际上希望测量世界的地方，并且为这个传感器开发软件。</p><p>但人类用来理解世界的还有其他的约束。</p><p>视觉最终是主要的那一个，但我们在参考我们对人类行为的理解和一些常识物理，这些从视觉，从知觉的角度可以推断出来。</p><p>但感觉我们在使用某种推理来预测世界，不只是像素。</p><p>我的意思是，你有一个强大的先验模型，对世界如何随着时间演变等有一定的预期。</p><p>所以不仅仅是来自数据本身的似然项告诉你你在观察什么，还有先验项，如可能看到什么内容以及它们可能如何移动。</p><p>问题是，在驾驶任务中的可能性范围有多复杂？</p><p>这对你来说仍然是一个未解决的问题吗，对驾驶有多难的哲学思考？</p><p>你在驾驶工作中花了那么多时间，你明白驾驶有多难吗？</p><p>驾驶真的很难，因为它涉及到对所有其他代理的预测，以及心智理论，知道他们会做什么，他们是否在看你，他们在看哪里，他们在想什么。</p><p></p><p>嗯，有很多事情在这个过程中进行，到最终我们需要适应的那个“尾部”，你知道的，也就是扩展的纳因斯问题，最终的问题就是那样的形态。我不认为这些是非常普遍的问题，我认为最终它们是重要的，但这真的只是尾部稀有的边缘情况。</p><p>从视觉的角度来看，驾驶时视觉问题中最难的部分是什么？</p><p>嗯，基本上传感器非常强大，但你仍然需要处理这些信息。所以，从这些像素亮度到这里的三维世界非常困难，这就是神经网络基本上在做的事情。因此，难点在于对整个管道、整个数据引擎进行极其出色的工程设计，具备训练这些神经网络的能力，能够评价系统并对其进行迭代。所以我会说，问题在于在生产中大规模完成这一切，这是一个执行问题。所以数据引擎，以及系统的部署，使其具有低延迟性能，它必须执行所有这些步骤。对于神经网络来说，确保一切都适合车载芯片是一个关键点。</p><p>你有一个有限的浮点运算预算并且有内存带宽和其他限制，并且必须确保它能运行良好，并且你可以尽可能多地将计算资源挤压到那个小空间。你从那个过程中学到什么？也许这也是从研究背景来的一个新的大挑战。</p><p>是的，我不确定是否有太多的见解。你尝试创建一个适合你所拥有的神经网络，并且你总是在优化它。我们在AI日上谈论了很多，基本上团队为了确保一切适配和利用引擎所做的非常复杂的工程设计。我认为这是非常好的工程学，然后也有各种小见解在如何正确地做这件事上。</p><p>我们实际上可以放大来看，因为我认为我们没有谈到数据引擎的整体布局，这个想法真的很美妙，有人类在环路中。你能描述一下数据引擎吗？</p><p>是的，我称之为几乎像生物一样的过程，通过它你可以完善这些神经网络的训练集。因为现在大部分的编程都在这些数据集的层面上，并确保它们是大、广泛且干净的。你有一个认为不错的数据集，你训练你的神经网络，部署它，然后观察它的表现如何。你试图总是提高你的数据集的质量，你试图捕捉那些基本上是稀有的场景。在这些场景中，神经网络通常会挣扎，因为在数据集中没有告诉它们在那些稀有情况下该做什么。但现在你可以关闭这个循环，因为如果你可以大规模收集这些数据，你可以将它们反馈到重建过程，并重建那些情况下的真实情况，并将其添加到数据集中。因此，整个过程最终变成了一个改进的阶梯，完善你的训练集。你需要通过部署来挖掘在数据集中还没有很好代表的部分。因此你的数据集基本上是不完美的，它需要多样化，它有漏掉的部分，你需要填补这些空白，可以这样想。</p><p>在人类系统中，人类在数据引擎中扮演什么角色？这个生物系统就像人体由细胞组成，人类系统中有多个工程师在合作，他们如何优化这个系统，决定要关注什么，贡献什么，优化哪个任务？</p><p>是谁在负责确定哪个任务需要更多数据？</p><p>你可以谈谈超参数吗，人类系统对这些超参数有何管理？</p><p>这真的取决于一个工程团队的极其良好的执行，他们理解数据引擎和系统改进的过程的哲学见解。他们明白如何有效地分配数据收集策略，并确保所有步骤都得到极好的执行。这是大部分工作的地方，不是哲学化的或研究或想法的地方。</p><p>这是一个非常出色的执行，当你处理这种规模的数据时，真的很难。</p><p>所以你在数据引擎中的角色执行得很好，这既困难又极其重要。</p><p>是否有类似远景板那样的优先级设定，比如说我们真的需要在红绿灯方面做得更好？</p><p>是的，任务的优先级设定基本上是通过数据来实现的，这是我们在产品中尝试实现的目标，从QA团队的反馈中获得的。</p><p>我们正在尝试发布的地图，系统在某些地方表现不佳，我们需要改进，而QA团队会提供一些信号和信息，综合作为对系统在各类条件下表现的反馈。</p><p>当然，我们还要自己驾驶系统并亲身体验，这也是很棒的，因为系统也能带你回家。</p><p>是否有一些你自己体验到的洞察，这些洞察是无法通过汇总统计数据分析得出的？</p><p>是的，这很奇怪，对吧？因为你只是一个个别样本，这在科学上不太严格。</p><p>我认为这是一种真相来源，是你与系统的互动。</p><p>你可以看到它，玩弄它，扰乱它，获得一种感觉，对它有直觉。</p><p>数字、图表和图形是很难的，它隐藏了很多东西。</p><p>比如训练一个语言模型，你与它互动是一种非常强大的方式。</p><p>埃隆也一直想自己驾驶系统，他每天都会驾驶，这是一种真理来源，系统驱动你，表现如何。</p><p>那么你怎么看这些棘手的问题呢？</p><p>去年，特斯拉取消了传感器套件中的雷达，现在又宣布将取消所有超声波传感器，仅依赖视觉，即仅使用摄像头。这会使感知问题更难还是更容易？</p><p>我几乎想以某种方式重新构建这个问题。情形是这样，你会认为额外的传感器是你的资产。</p><p>顺便说一下，我可以打断一下吗？我想知道语言模型是否会做到这一点，如果你提示它让我重新构建你的问题，那会很史诗。这是个错误的问题。</p><p>对不起，这有点像个错误的问题，因为基本上你会认为这些传感器对你有帮助。</p><p>但如果你完全考虑整个产品的整体性，这些传感器实际上可能成为负担。</p><p>因为这些传感器不是免费的，它们不会凭空出现在你的车上。你需要整个供应链来获得它们，有时候还可能会出问题，可能需要更换，它们也是制造过程的一部分，可能会拖慢生产线的进度。</p><p>你需要采购它们，维护它们，还需要团队编写固件等等，此外你还需要将它们以某种方式整合到系统中，所以这其实增加了组织的负担。</p><p>埃隆非常擅长简化，最好是没有部分。所以他总是尝试丢弃不必要的东西，因为他了解在组织中维持秩序和简化的重要性。</p><p>在这种情况下，代价很高，你可能察觉不到如果你只是一个计算机视觉工程师，只是尝试改进我的网络，不管它是否更有用。</p><p>但实际上当你考虑一个传感器的全部成本时，它很可能是负担，你必须非常确定它提供了极其有用的信息。</p><p>我们看了使用和不使用传感器的差异，发现并不显著，所以它没有用。</p><p>更多的传感器是否也会增加数据引擎的负担？</p><p>这些传感器可以随时间变化，例如你可能有一种类型的雷达，你可能还有其他类型的雷达，它们随时间变化，我忽然需要担心这个问题。</p><p>现在你的sqlite突然有一列告诉你是哪种传感器类型，它们都有不同的分布，它们增加了噪声和干扰，并且增添了复杂性。</p><p>从组织角度来看，这也非常有趣，它可能非常分散注意力。</p><p>但如果你只希望视力系统能够工作，那么所有的资源都会集中在这一目标上。</p><p>而你正在构建一个数据引擎，你实际上在取得前进，因为那是拥有最大带宽和对世界有最多约束的传感器，而你完全集中投资于它，并让它变得非常好。</p><p>如果你有有限的注意力在系统的不同方面进行分散，这让我想起了Rich Sutton的“苦涩教训”，这似乎是在简化系统。</p><p>从长远来看，当然你不知道长远是什么，但似乎总是正确的解决方案。</p><p>是的，在那种情况下，这是4RL，但它似乎普遍适用于所有进行计算的系统。</p><p>那么，你怎么看激光雷达作为拐杖的争论？</p><p>云点和像素之间的战斗。</p><p>是的，我认为这个争论对我来说总是有点混乱，因为真正的争论似乎应该是你是否拥有车队，这才是关于你能否在这个规模上实现AI系统真正良好运作的重要问题。</p><p>数据收集系统。</p><p>是的，你有没有车队是远比你是否有激光雷达更重要的事情，它只是另一个传感器。</p><p>是的，我认为与雷达讨论类似，基本上我不认为这基本上没有提供额外的信息，非常昂贵，有各种各样的问题，你必须调整校准它等等，它会制造臃肿和熵，你必须非常确定你需要这个传感器，在这种情况下，我基本上认为你不需要它。</p><p>老实说，我会下一个更强的结论，我认为其他一些公司正在使用它，可能会放弃它。</p><p>所以你必须在考虑能否建立一个大型车队来收集大量数据时考虑这个传感器，并且你能否将那个数据和传感器整合到一个数据引擎中，该数据引擎能够快速找到数据的不同部分，并持续改进你使用的模型。</p><p>另一种看法是视觉在某种程度上是必要的，因为世界是为人类的视觉消费设计的，所以你需要视觉是必要的，它也足够了，因为它包含你驾驶所需的所有信息，人类显然用视觉来驾驶，所以它既是必要的也是充分的。</p><p>所以你要集中资源，如果你要引入其他传感器，你可以无限制地增加传感器，某个时候你需要画出界限。</p><p>在这种情况下，你必须真正考虑你采用的任何一个传感器的全部成本，是否真的需要它，我认为答案是否定的。</p><p>那么，你怎么看待其他公司形成高分辨率地图并严重限制它们操作的地理区域的想法？</p><p>在你看来，这种方法不会随着时间推移在整个美国范围内扩展吗？</p><p>我认为他们的方法是预先映射所有环境并需要刷新地图，并且他们拥有他们将驾驶的每个地方的完美厘米级精确地图，这很疯狂。</p><p>当我们谈论自动驾驶真正改变世界时，我们说的是全球范围内部署用于运输的自主系统，如果你需要维护一个地球或很多城市的厘米级精确地图并保持它们更新，这是一个巨大的依赖。</p><p>这是一个庞大的，巨大的依赖，现在你需要问自己是否真的需要它。</p><p>人类不需要它。</p><p>所以，拥有一个低层次的地图，比如你的道路连接情况还是非常有用的，你知道即将出现一个岔路口，当你驾驶环境时，你会有那种高层次的理解，比如一个小的Google地图，特斯拉使用类似谷歌地图这种分辨率的信息在系统中，但它不会预先映射环境到厘米级精度，这是一个拐杖，是一种分散注意力的东西，它会带来熵并稀释团队，你没有集中精力在真正需要解决的计算机视觉问题上。</p><p>你从与Elon Musk合作中学到了什么关于机器学习、工程、生活以及作为一个人类自身的东西？</p><p>我觉得我学到最多的是如何高效管理组织以及如何创建高效的组织，如何在组织中与熵作斗争。</p><p>在人类工程中与熵作斗争。</p><p>是的，我认为Elon是组织中对抗熵的一位非常高效的战士。</p><p>在组织中熵是什么样子的？</p><p>是流程，是流程和效率低下的那些东西。</p><p>对,会议他讨厌 
会议他不断告诉人们如果会议没用就跳过.
他说他基本上经营着世界上最大的 
创业公司，我会说，特斯拉和SpaceX是世界上最大的创业公司，特斯拉其实有多个创业公司，我认为从这个角度看会更好，
所以我认为他在这方面非常擅长，
对，他对简化流程有非常好的直觉，使一切都高效，无部件就是最好部件，简化，专注，
并且在消除障碍方面做得很好，
行事非常快速，做出重大决策，这些都是具有创业气息的事情，但是在规模上如此大的公司中执行。
对于我来说，从你的角度来看，
这可能也适用于设计系统和机器学习以及其他方面。 
是的，简化，简化。
你认为在公司成长时保持创业文化的秘密是什么？ 你能反思一下吗？
我确实认为你需要一个拥有强大权力和影响力的人，比如埃隆，他是这个理念的鼓吹者，并无情地追求它。
如果没有人拥有足够的权力，一切都会变成委员会、公司内部的民主、与利益相关者对话、决策，一切都崩溃了。
如果你有一个既聪明又有很大影响力的人，事情会进展得很快。
你说你在《星际穿越》中最喜欢的场景是AI和库珀对话的紧张对接场景，库珀说，
库珀，你在做什么？ 对接是不可能的，不，它是必要的，
顺便说一句，这是一个很好的台词, 有很多问题，为什么那个场景中的AI
应该能够计算出比人类更多的信息，说不可能，为什么人类呢？ 我们知道这是一部电影，但AI不应该比人类更了解吗？
无论如何，你认为设定看似不可能的目标有什么价值？
所以，比如我们的初始直觉，看起来像是你和埃隆主张的那种观点，社区的初始直觉可能会说这是非常困难的，然后你还是接受了， 设定了一个疯狂的期限，从人类工程学的角度。
你看到这有什么价值吗？
我不会说设定不可能的目标是好主意，但我认为设定非常雄心勃勃的目标是好主意，我认为这是一种我称之为的非线性难度扩展， 这意味着10倍的问题通常不是10倍难度，通常10倍难度的问题执行起来就像是2到3倍左右的难度，因为如果你想要实际提高系统10％，需要一些工作，如果你想提高10倍，并不需要100倍的工作量，因为你彻底改变了方法，如果你带着这个约束开始，那么一些方法显然是愚蠢的，不会起作用，迫使你重新评估。
我认为这是一种非常有趣的问题解决方式，但它需要一种奇怪的思维方式，这就像回到你的博士时期，这就像你如何思考在机器学习社区中哪些想法是可以解决的，确实需要，这是什么？ 我们有一个精简口号叫基础原理思考，但这需要基本上忽略社区的观点，因为社区通常会在科学上划定什么是可能和不可能的界限，很难在不疯掉的情况下突破这一点，是的，我认为这里有一个很好的例子就是所谓的深度学习革命，因为你可以在那个时候进入计算机视觉领域，在2012年的深度学习革命期间，你可以将你的计算机视觉栈提升10％，或者你可以说实际上这些都没用，我如何做10倍更好的计算机视觉呢？ 那么这可能不是通过调整特征检测器的办法，我需要一种不同的方法。
我需要一些可扩展的方法，回到理查德·萨顿的理解，理解所谓痛苦教训的哲学，然后说实际上我需要一个更可扩展的系统，比如神经网络，原则上是可行的，然后有一些深度信仰者实际执行这个任务并使其成功。
那么这是10倍解决方案。
你认为解决自动驾驶问题的时间表是什么?
这在很大程度上仍是一个悬而未决的问题。
是的，我认为自动驾驶的时间表的难题显然是，因为没有人创造过完全自动驾驶。
所以这不像建桥，你认为建这座桥的时间表是什么？好吧，我们建造过许多桥，这需要多少时间是很确定的。</p><p>你知道，这个...没有人真正实现过自主驾驶。这并不明显，有些部分最终比其他部分要容易得多。因此，很难预测。你尽最大努力根据趋势线等进行预测，并基于直觉进行预测，但这就是为什么从根本上来说这真的很难预测。甚至身处其中的你也难以做到。</p><p>是的，有些事情最终比预期的要难得多，有些事情则比预期的要容易得多。</p><p>你是否尽量避免做出预测？因为像Elon这样的人并不回避预测，是吗？过去的汽车公司领导人也没有回避预测。比如福特和其他公司曾预测我们将在2020年、2021年左右解决四级自动驾驶问题，但现在他们都在收回那个预测。</p><p>作为一个AI专家，你会在私人场合做出预测吗？还是这些预测会影响你真正思考问题的能力？</p><p>是的，我会说容易说的是这个问题是可以解决的，这是一个容易做出的预测。可以解决，这会奏效。是的，可有些事情真的很难，有些事情则容易得多。至少在Tesla内部，我确实看到团队正朝着那方向前进。</p><p>你如何形成一个强有力的表示，以便对可行性进行预测？比如，你是很多人的领导者，你必须说这确实是可能的。你如何建立这种直觉？这不一定是驾驶方面的任务，可以是其他任务。</p><p>我好奇你在生活中曾经处理过的困难任务，像是分类、达到一定层次的超级人类级别的表现。这是专家直觉，这是直觉，这是一种信念。</p><p>就像你说的那样，只要思考足够长时间，研究看样本数据，驾驶等。我的直觉在这方面真的很有缺陷。我对可行性没有好的直觉。它可能是任何东西，它可能是可解决的。比如，驾驶任务可能被简化成非常琐碎的问题，问题的解决方案会非常琐碎，并且规模上更多的车像完美驾驶一样驾驶，可能会使问题容易得多。</p><p>是的，车越多，大家学会如何正确驾驶，不是正确而是更优化的方式，对异构的自动/半自动和手动驾驶车系统可能会改进。然后我又花了大量时间观察行人过马路，思考人类，这感觉就像我们通过眼神接触发送了强烈信号。存在某些行为的怪癖和特例，当然，大多数死亡事故涉及醉酒驾驶，行人和司机双方都可能。还有夜间驾驶问题等。</p><p>我想知道的是，自动驾驶可能的解决方案空间包含了如此多的人的因素问题，几乎不可能进行预测。可能会有超级干净漂亮的解决方案。</p><p>是的，使用游戏的类比，有一些战争迷雾，但你确实看到改进的前沿，并且能够测量到历史上取得了多少进展。我例在 Tesla 的五年时间里举个例子，当我刚加入时，车子几乎不能在高速公路上保持车道。从Palo Alto开到旧金山(SF)，每当道路几何改变或者转弯太多时，可能需要三到四次干预，车子根本无法工作。而现在，五年后，系统已经相当有能力，并且看到内部的进展以及团队在数据、计算等方面的规模操作，这是一个巨大的进步。</p><p>你正在登山，虽有迷雾，但你在不断进步。你在前进，并且看到下一步方向，你看到剩下的一些挑战，它们不会影响你，它们不会改变你的哲学，也不会让你扭曲自己。你会想，这些是我们仍需完成的事情。解决问题的基本组件似乎都存在，从数据引擎到计算、车上的计算机，再到训练的计算等等。</p><p>你做了很多惊人的突破性想法和工程，从数据引擎到人性方面。请谈谈你为什么选择离开特斯拉。基本上正如我所描述的那样，我觉得随着时间的推移，在这五年间，我开始有点进入了管理层的位置。我的大部分日子都是开会，发展组织，并做出关于团队应该从事什么工作方面的一些高层战略决策。</p><p>这有点像一个企业高管的角色，我觉得我可以做这个，我也认为我在这方面还算可以，但这并不是我真正享受的东西。所以，当我加入时，根本没有计算机视觉团队，因为特斯拉刚从使用Mobileye这个第三方供应商为所有计算机视觉系统转向自己构建自己的计算机视觉系统。当我到达那里时，有两个人正坐在他们的电脑前训练深度神经网络，他们正在进行一些基本的分类任务。</p><p>后来我把这个团队发展成了一个相当有声望的深度学习团队，建立了一个庞大的计算集群和一个非常优秀的数据注释组织，我对这个成就非常满意，这个团队变得非常自主，因此我选择离开。我非常期待能够再次从事更多技术性的工作，并重新聚焦于AGI（通用人工智能）。</p><p>在你探索自我的过程中，你做了些什么，因为你花了一些时间思考。你吃了多少蘑菇？不，我是说，你脑子里在想什么？人的一生是有限的。你做了一些令人难以置信的事情，你是全世界最优秀的AI教师之一。你的意思是理解事物的基本原理，通过从头开始构建它并用基本的直觉来进行探索。比如爱因斯坦和费曼都非常擅长这种事情：通过一个小的例子来理解并尝试去使用它。</p><p>显然，现在你帮助建立了一个机器学习团队，和一个实际在现实世界中取得成就的系统。所以，考虑到所有这些，自我探索是怎样的？</p><p>这很难，因为显然我非常喜欢这家公司，我非常喜欢Elon，非常喜欢特斯拉。我非常喜欢这个团队。因此，离开是非常艰难的。</p><p>实际上，我可能会有兴趣重新审视这个问题，也许在某个时候回到特斯拉，参与Optimus或AGI的工作。我认为特斯拉会做出令人难以置信的事情，这是一家大规模的机器人公司，内部有大量的才华横溢的人才，能够做出真正难以置信的事情。人形机器人将会非常令人惊叹，我认为自动驾驶交通也会非常难以置信，这些所有的事情都在特斯拉进行。因此，这是一个非常惊人的组织，能够成为其中的一部分并帮助它前进，我非常享受。</p><p>正是因为我非常喜欢这家公司，所以离开是很困难的。但我很高兴可能在某个时候能回来开启“第二幕”。但我感觉在这个阶段，我已经建立了团队，而且团队显得很自主，我变成了一名管理者，而我想要做更多技术性的工作，我想要学习东西，想要教授东西，所以我觉得这是改变节奏的一个好时机。</p><p>谈到第二部分，历史上最好的电影续集是什么，因为大多数电影续集都很差。你经常在推特上谈论电影。你最喜欢的电影续集是什么？</p><p>《教父2》。</p><p>你是《教父》的粉丝吗？因为你甚至没有在推特上提到过《教父》。我不太喜欢那部电影。我们会把这个删掉，把对《教父》的不满删掉。你怎么敢这么说。我会做一个强烈的声明，我不知道为什么，但我基本上不喜欢任何1995年之前的电影。</p><p>你提到《终结者2》。那部电影是在1990年左右。是的，《终结者2》是个稍晚一些的电影。而且我也喜欢《终结者1》。因此有一些例外，但总的来说，出于某种原因，我不喜欢1995年之前的电影，它们感觉非常慢，镜头拉得很远，很无聊，有点天真，有点奇怪。同时，《终结者2》非常超前于它的时代。还有《教父》里没有AGI。</p><p>你提到了《心灵捕手》（Good Will Hunting），这部电影里也不存在AGI，我猜这是数学。</p><p>我猜偶尔我会喜欢一些不涉及或像《活宝》中没有太多技术的电影。《活宝》真的很棒，我不理解，嗯，说到通用人工智能，我不理解为什么威尔·法瑞尔这么搞笑，这没有道理，这个笑点无法被算出来。他身上就是有某种特质，他是个独特的人，因为现在你不会看到太多喜剧电影，我在想这是否和文化或者好莱坞的运作机制有关，还是我们只是幸运地遇到了某些人和喜剧碰撞到了一起，因为他是个独特的人。</p><p>这真是个荒谬的跑题，对不起，但你提到了类人机器人，那么你对Optimus（特斯拉机器人）有什么看法，你认为我们在10年、20年、30年、40年、50年内会在工厂或家庭中拥有机器人吗？</p><p>是的，我认为这是一个非常难的项目，我认为这需要一段时间，但还有谁会规模化地构建类人机器人呢？我认为这是一个非常好的形式因素去追求，因为正如我提到的，世界是为类人形式设计的。这些东西将能够操作我们的机器，能够坐在椅子上，甚至可能驾驶汽车，基本上世界是为人类设计的，这是你要投资并且随着时间推移去实现工作的形式因素。我认为还有另一种思路是选择一个问题并为其设计一个机器人，但实际上设计一个机器人并让整个数据引擎和背后的所有东西协同工作实际上是一个非常困难的问题。因此，追求一种通用接口是有道理的，虽然它们对任何一个具体任务并不完美，但它们实际上具备了一种广泛性，只需用一种提示，通过英语能够跨领域做一些事情。因此，我认为去追求一种通用物理界面的目标是很有意义的，我认为这会是一个非常困难的项目，我认为这会花时间，但我看不到有其他公司能实现这一愿景。我认为这将是惊人的，比如，基本上物理劳动，如果你认为运输是一个大市场，试想一下物理劳动，简直疯狂。</p><p>对我来说，令人兴奋的不仅是物理劳动，还有社交机器人。所以我们与这些机器人在不同层次上的关系也很令人兴奋。这就是为什么我看到Optimus会很兴奋。人们批评我对这些东西的兴奋，但我曾与许多研究实验室合作，他们研究类人腿机器人，比如波士顿动力、Unitree以及很多做腿机器人的公司。但优雅的动作只是整个大画面的一个很小的部分。</p><p>对我来说，特斯拉做类人或任何腿机器人的两大令人兴奋的事情是：显然将其整合到数据引擎中，所以数据引擎的部分，即实际的感知、控制和规划的智能方面，整合到你提到的庞大车队中。然后谈到车队，第二件事是大规模生产，只知道文化上的驱动是为了简单的机器人，能够廉价地大规模生产，并做好这件事，有经验做到这一点能改变一切。</p><p>这就是为什么这与波士顿动力的文化和风格非常不同，顺便说一下，那些机器人的动作方式是如此优雅，特斯拉要实现那样的平滑动作还需要很长时间，但这不是重点，重点是整个系统，就像我们谈到的数据引擎和车队一样超级令人兴奋，即使是最初的模型，但在几个月内能得到一个原型也是非常令人惊讶的。之所以能这么快实现，是因为正如你提到的，有大量借鉴了自动驾驶的经验的原因。</p><p>是的，
在特斯拉出现的建设人类机器人方面的专业知识数量令人难以置信。</p><p>基本上，
埃隆在某个时候说我们要做这个，
然后第二天，
所有这些CAD模型开始出现，
人们开始谈论供应链和制造。</p><p>有一天有人带着螺丝刀等工具来了，
开始组装机器人，
而我当时心想，
哇，这些人都在特斯拉工作。</p><p>从根本上讲，制造一辆车实际上与制造一个机器人没有太大的区别。</p><p>这不仅适用于硬件部分，也不要忘记硬件不仅用于演示，
大规模制造硬件是完全不同的事情，
还适用于软件。</p><p>基本上，这个机器人目前认为自己是一辆车，
它将在某个时候经历中年危机，
它认为自己是一辆车。</p><p>一些早期的演示实际上我们在讨论是否在停车场外进行，
因为那里的计算机视觉可以开箱即用，而不是在室内。</p><p>所有的操作系统都可以复制粘贴，
计算机视觉大部分也可以复制粘贴，
尽管您需要重新训练神经网络。</p><p>在数据引擎和离线跟踪器以及我们处理占用跟踪器的方式上，
一切都可以复制粘贴，只需重新训练神经网络。</p><p>当然，规划控制必须发生相当大的变化，
但很多东西都可以从特斯拉移植过来。</p><p>所以，如果你的目标是建造一百万个人类机器人，
而你不是特斯拉，
那是一个很大的挑战。</p><p>但如果你是特斯拉，
那就没那么疯狂了。</p><p>接下来的问题是，
就像驾驶一样，
操作任务有多困难，
以至于它可以大规模产生影响？</p><p>我认为这取决于具体情境，
机器人领域的好处在于，
除非是在制造业等方面，
否则有更多的容错空间。</p><p>驾驶是非常安全关键的，也是时间关键的，
而机器人被允许移动较慢，
这点很好。</p><p>我认为这将需要很长时间，
但要设定产品开发路线图，
确保你在此过程中产生收入。</p><p>不要把自己置于零一损失功能的位置，
即：要么完全没用，要么完全有效。
你不想处于那种情况，
你要让它几乎立即有用，
然后逐步部署到大规模。</p><p>你要设置你的数据引擎，
改进循环，
遥测，
评估和所有工具，
正确地改进产品并在此过程中赚钱，
因为否则你无法进行这些大规模项目，
这在经济上是没有意义的。</p><p>从团队角度来看，
他们需要在过程中获得多巴胺激励，
他们不会仅仅为了十年后有用而努力，
你不希望这样。</p><p>你希望它像现在的自动驾驶仪一样，
它今天提供了更高的安全性，
驾驶的便捷性，
人们为它付费，
人们喜欢它和购买它，
并且你也在朝着更大的目标努力。</p><p>团队的多巴胺激励来源是，
你在部署这个，
人们喜欢它，
开车的人支付它，关心它。</p><p>有很多YouTube视频，
你的奶奶开它，她给你反馈，
人们喜欢它，与之互动，
你与它互动。
这是巨大的。</p><p>驾驶特斯拉的人会认出你并表达爱意，
如：嘿，
谢谢你提供的这个很好的功能。</p><p>我认为棘手的是：
有些人真的很爱你，
但不幸的是，
你正在从事一些你认为非常有价值和有用的事情，
有些人却讨厌你。</p><p>很多人讨厌我和我的团队及整个项目，
我认为他们其实是特斯拉的车主，
但实际上很多情况并不是这样。
这让我对人类互动方式感到难过。</p><p>我认为这实际上是可以修复的，
人类想要对彼此好，
我认为Twitter和社交媒体其实是部分机制，
它使得消极性更容易传播，
但却不值得那种不成比例的病毒性推动。</p><p>但我希望人们能够感到兴奋，压抑一些嫉妒和自负，对别人的成就感到兴奋。</p><p>然后有一个因果报应的层面，你为别人感到兴奋，他们也会为你感到兴奋。</p><p>在学术界也是一样，如果你不小心，在一个孤立的系统中工作，嫉妒别人的成功，这实际上会，可能听起来矛盾，但会导致你和你的社区生产力的下降。</p><p>我觉得，如果你一直在庆祝别人的成就，这实际上也会让你变得更成功。</p><p>我认为人们在不同的行业中，还没完全学到这一点。</p><p>有些人也非常消极和高调，所以他们被显著地关注到，但实际上有很多人是沉默的啦啦队员。</p><p>当你与世界上的人交谈时，他们都会告诉你，这很棒，尤其是那些理解让这些东西工作有多困难的人，比如那些建造产品的人、制造者和企业家，制作这些东西并改变一些事情是非常困难的。</p><p>这些人更有可能支持你。</p><p>其中一件让我感到难过的事情是，一些机器人社区的人们，没有做啦啦队员的角色，而他们应该这样做。</p><p>因为他们知道这有多难。</p><p>实际上，有时他们不知道在实际规模上创造一个产品有多难。</p><p>在现实世界中实际部署很多机器人和 AI 系统的开发是针对非常特定的小基准测试进行的。</p><p>而不是面对现实世界的条件。</p><p>在学术环境中从事机器人或者适用于现实世界的AI系统是非常困难的。</p><p>你批评过但同时也喜欢和热爱过一段时间的Imagenet，即著名的Imagenet数据集。</p><p>我最近听到了一些批评的声音，认为学术研究机器学习社区仍然过于关注Imagenet或类似的基准测试。</p><p>你能谈谈在机器学习研究中使用的数据集的优缺点吗？</p><p>其实我不记得我曾对Imagenet表示不满或批评，我认为Imagenet极其有价值。</p><p>它基本上是一个基准，让深度学习社区可以展示深度神经网络确实有效。</p><p>这是非常有价值的。</p><p>所以我认为Imagenet是有用的。</p><p>但基本上它现在有点像EMNIST数据集了。</p><p>EMNIST是一种28x28灰度的数字数据集，有点像一个笑话数据集，每个人都轻松搞定的那种。</p><p>不过没有人在EMNIST上写文章了，对吧？</p><p>也许他们应该写关于如何在少量数据下学习的有力文章，这类内容。</p><p>我可以看到这对某种计算机视觉研究仍然有用。</p><p>我可能在哪儿听过你的这些话，也许只是我想象的，但我想你说过Imagenet对社区做出了巨大贡献，现在是时候超越这些基准了。</p><p>Imagenet确实被攻克了。</p><p>比如，错误率已经非常低。</p><p>我们现在在1000类分类中有90%的准确率。</p><p>我看过这些图片，确实非常高的准确率。</p><p>如果我记得正确的话，Top 5错误率现在大概是1%或更低。</p><p>根据你在处理巨大现实世界数据集的经验，你希望研究社区的基准测试朝哪些方向发展？</p><p>不幸的是，我不认为学术界目前拥有下一个Imagenet。</p><p>我们显然已经攻克了mnist，基本上也攻克了Imagenet，但没有下一个大规模基准让整个社区团结起来继续发展这些网络。</p><p>要吸引所有人的想象力，让他们都加入进来的数据集需要什么？那也需要像一个领导者那样的病毒式传播，某个有影响力的人。</p><p>为什么图像处理突然兴起？</p><p>这只是历史的偶然吗？</p><p>它的难度是否恰到好处？</p><p>是的，难度刚刚好，不多不少，同时也够简单又有趣，这样的数据集在当时正合时宜。</p><p>来自Reddit的提问：</p><p>关于合成数据和游戏引擎在未来神经网络模型开发中所扮演的角色，您有什么看法？</p><p>我认为：</p><p>当神经网络趋向于人类时，</p><p>模拟对神经网络的价值将类似于模拟对人类的价值。</p><p>人们使用模拟是因为他们可以在这种系统中学习东西，而不必实际经历它。</p><p>但你指的是我们在脑中进行的模拟吗？不，不是这个意思。而是像电子游戏或各种专业用的其他形式的模拟。</p><p>好吧，让我反驳一下，因为也许我们在脑内进行的模拟，比如“如果我这样做，会发生什么”？</p><p>对，这是一种内部模拟，但是这和我们使用的计算机游戏或用于训练集创建的模拟有区别吗？</p><p>它是否是独立的，还是只是松散相关的？比如说，</p><p>做反事实假设或极端情况模拟是否有用？</p><p>比如，如果发生核战争会怎样，如果发生这些事情会怎样？</p><p>这和像Unreal Engine那样的模拟是不同的，我是这么理解这个问题的。所以模拟平均情况，</p><p>这就是Unreal Engine的意思吗？你说的Unreal Engine是什么？</p><p>模拟一个世界，是指那个世界的物理规律。</p><p>为什么不同？因为你也可以为那个世界添加行为，可以尝试各种事情，对吧？</p><p>Unreal Engine不仅仅是模拟世界的物理现象，还做了一些其他的事情。</p><p>是的，图形、物理和你放入环境中的智能体等等。</p><p>因此，我觉得你是在说它对未来的AI发展不那么重要，这样理解对吗？</p><p>我认为人类认为模拟器有用，</p><p>计算机也会认为模拟器有用。</p><p>好的，所以你是说我不太常用模拟器，每隔一段时间我会玩电子游戏，但我不认为从这些电子游戏中学到了任何关于自身存在的智慧。</p><p>这些只是短暂逃避现实，而不是关于现实的智慧来源。</p><p>因此，我认为这是一种非常客气的方式说模拟器没有那么有用。</p><p>是的，也许是，也许不是。我不认为它目前是训练神经网络的一个根本、非常重要的部分。</p><p>但我认为，随着神经网络变得越来越强大，你将需要更少的例子来训练额外的行为，而模拟器当然是有一种域差距的，模拟器并不是真实世界，有些许不同的地方，但是随着神经网络变得足够强大，</p><p>域差距可以变得更大，因为神经网络会明白即使这不是现实世界，它仍具有我应当能够学习的这些高层次结构。因此你将能够</p><p>更好地利用合成数据，能够更好地理解数据不真实的方面。</p><p>好的问题，下一次问得更好，开个玩笑。</p><p>你认为是否可能构建需要非常少数据的神经网络和训练过程？</p><p>我们一直在谈论大数据集，比如互联网来进行训练。我是说，如你所说的，查询本身也是另一个层次的训练，这需要很少的数据。</p><p>但你认为研究一下是否有价值，看看我们能否用非常少的数据来训练构建知识库？</p><p>我只是
觉得在某个时刻，你需要一个
大型的数据集，然后当你
预训练你的大型神经网络
并获得某种类似GPT的东西时，
你就能够非常有效地训练任何任意的新任务。
这样很多这些GPT
你可以只用很少的例子就完成任务，比如情感分析或翻译等等，
只需提示它“这是我想让你做的事”，比如“这是一个输入句子，这是翻译成德语的句子，输入句子，德语翻译，输入句子，空白”，
神经网络就会根据你提供的示例完成翻译成德语的任务。
这是一个非常少样本学习的例子，
在神经网络的激活函数中，而不是神经网络的权重中。
所以我认为
基本上，就像人类一样，神经网络将非常数据效率地学习任何其他新任务，但在某个时刻，
你需要一个大型数据集来预训练你的网络，
以得到那个效果，而且人类可能也有类似的东西。
我们有没有这样的东西呢？我们有没有一个在后台运行的被动的
背景模型构建东西以一种
自监督的方式运转，而我们不自觉呢？我认为人类肯定有，因为
显然我们在我们的一生中学习了很多，
但我们也有大量的硬件帮助我们初始化，
这种初始化是来自于进化。所以我认为那也是一个很大的成分。
很多领域里的专家认为他们只是谈论人类
在一生中所经历的秒数，
假装这是一个纯白板，
一种神经网络的零初始化，
事实上并不是这样。你可以看看很多动物，比如斑马。
斑马一出生就能看到东西，并且能跑。在它们的生命中没有任何训练数据，但它们就是能做到这些。
所以不知怎么的，我不知道进化是如何把这些算法和这些神经网络的初始化编码得如此之好，
而对此我完全没有头绪，
但显然这是可能的，因为这是存在的证明。从单细胞到生物体的过程中有某些神奇的事情发生，
然后到出生后的头几年的生命中。
我有点喜欢这个想法，即我们不记得生命的头几年是因为那个过程非常痛苦，
就像一个非常困难和挑战性的
训练过程一样，或者说
相对于智力方面。
或许是的，我不知道为什么我们不记得那些事情。
可能是一些疯狂的训练正在进行，
也许那就是在后台进行的模型训练，很痛苦，
所以系统在训练后最好不记得它是如何构建的。
我认为只是因为
长时记忆的硬件还没有完全开发好。
我有点觉得婴儿前几年的
实际上不是学习，而是大脑在成熟。
我们早产了。
有一种理论是，因为产道和大脑的肿胀，
所以我们早产，然后头几年只是大脑在成熟，然后才开始学习。
这是我目前的看法。你怎么看？你认为神经网络可以有长时记忆吗？
就像人类那样，你认为你需要在其之上加上另一个元架构来添加知识库吗，
那种学习世界事实的东西？是的，但是我不知道
它会在多大程度上被明确构建。
它可能会呈现出非直观的形式，
比如告诉GPT“嘿，你有一个声明性记忆库，可以存储和检索数据，
每当你遇到你认为有用的信息，就把它储存在你的记忆库中，这里是你检索到的信息的例子
以及如何说它，以及如何从中加载它。你只需说‘加载’”，
用文本以英语教授它，然后它可能会
学会使用记忆库。
噢，所以神经网络是背景模型的架构，基本的东西，
然后是的，其余的一切都构建在它之上。
它不仅仅是文本而已，你在给它小工具和
装置，
你在用某种特殊的语言教授它，从而使它能够存储任意信息，并在以后检索它，
告诉它这些特殊的符号以及如何排列它们来使用这些接口。
就像“嘿，你可以使用计算器，以下是使用方法，只需输入‘五 三 加 四 一 等于’，
当等号在那时，
计算器实际上会读出答案，
你不需要自己计算。”</p><p>你只需用英语告诉它，这实际上可能是可行的。</p><p>你认为在这个意义上，Gato是有趣的吗？那个Deep Mind系统不仅仅是新的语言，而是将一切都放在同一个堆里，包含图像、动作等等。这基本上就是我们正在迈向的方向。</p><p>是的，我认为是这样的，Gato以一种厨房水槽方法进行强化学习，在许多不同环境中使用一个固定的Transformer模型。</p><p>我认为这是该领域内一个非常早期的结果，但我认为这是事情最终将会看起来的样子。</p><p>从一个严格的Rich Sudden观点看，现在正是一个系统最终会看起来类似的早期阶段。</p><p>我不太喜欢所有这些看起来非常不同的界面。</p><p>我希望一切都能够归一化到相同的API，比如说屏幕上的像素，而不是拥有不同的世界环境，不同的物理和关节配置、外观等等。</p><p>你在不同游戏中插入某些特殊标记，我宁愿将一切归一化到单一接口，这样它在神经网络看来是相同的，如果这有意义的话。</p><p>所以最后一切都会是基于像素的乒乓球，我认为是这样的。</p><p>好，让我问问你的个人生活。</p><p>很多人想知道，你是AI历史上最有生产力和最聪明的人之一，Andrej Karpathy，你的一天是怎样的？</p><p>你几点钟起床？我能想象到某种在平均和完美生产力之间的舞蹈。</p><p>所以完美的生产力是我们努力追求的东西，而平均生产力是我们随着所有的错误和人类的不可预见性所趋向的。</p><p>你是早起的人吗？</p><p>我不是一个早起的人，我确实是一个夜猫子。</p><p>无论稳定与否，我通常是8点或9点左右起床。</p><p>在攻读博士期间，起床时间甚至更晚，我通常凌晨三点上床睡觉。</p><p>凌晨的小时是宝贵且非常有趣的工作时间，因为每个人都在睡觉。</p><p>在早上8点或7点时，东岸已经醒了，所以已经有活动了，有些短信之类的东西在发生，有些新闻网站上已经有内容了，这是很分散注意力的。</p><p>而在凌晨三点，一切都非常安静，所以你不会被打扰，你有整块的时间来进行工作。</p><p>所以，我喜欢这些时间段，夜猫子是默认设置，然后我认为生产的时间基本上是这样：</p><p>你需要在问题上积累一些动能，不要有太多的干扰；</p><p>你需要将你的工作记忆载入那个问题，</p><p>然后你需要对它痴迷，当你洗澡或者入睡时，你要想着那个问题，它完全在你的记忆里，你醒来时就可以直接重新投入工作。</p><p>这是一个时间尺度，是一天还是几天，一个星期，一个月？</p><p>我不能单独谈论一天，因为这是一个整体的过程。</p><p>当我想在一个问题上变得富有生产力时，我感觉我需要几天的时间来彻底进入那个问题，我不想被打扰，我会全身心地沉浸于那个问题中，这就是我做大多数好工作的方式。</p><p>你完成了很多非常酷的小项目，时间很短，很快完成，所以这需要你集中注意力。</p><p>基本上，我需要在记忆中载入我的问题，这样才能变得富有生产力，因为处理任何问题总有一个巨大的固定成本。</p><p>举个例子，我在特斯拉时遇到困难，因为我想做一些小型副项目，但首先我需要弄清楚如何SSH进入我的集群，我需要启动一个VS代码编辑器，这样才能工作，我会因为某些原因遇到愚蠢的错误。</p><p>你不能马上变得有生产力，你面对的是障碍，所以要做到真正消除所有这些障碍，你能够进入问题的状态并将整个问题载入记忆中，同时避免各种不同形式的分心：比如新闻故事、电子邮件，还有先前或目前工作的其他有趣项目。</p><p>你只是想真正专注于你的思维，我可以在中间抽出一些时间分心，但不能太多。</p><p>你大部分时间都是花在那个问题上。</p><p>然后你知道，我喝咖啡，有我的晨间例行活动，我看一些新闻，比如Twitter、Hacker News、《华尔街日报》等等。</p><p>所以基本上你醒来后喝杯咖啡，尽快开始工作，你会先看看这个世界发生了什么吗？</p><p>是的，我确实发现了解世界很有趣，我不知道这是否有用或者是否好，但这是我目前的日常习惯之一。所以我会读很多新闻文章，我想保持信息通灵。</p><p>我对此持怀疑态度，我怀疑这种做法。</p><p>哦，你是说怀疑这种做法对你的生产力和幸福感的正面影响？</p><p>对我的心理健康有怀疑，还有对你深入理解世界的能力，因为有很多信息来源，你并没有真正专注于深度整合。</p><p>是的，这有点分散注意力。</p><p>关于一个完全高效的工作日，你会尝试在一次工作和专注于某件事上持续多长时间？</p><p>几个小时吗？是一小时还是30分钟，还是10分钟？</p><p>我可能可以持续工作几个小时，然后需要一些休息时间，比如吃饭等等。</p><p>是的，但我认为即使是这样，积累工作时间仍然非常困难。我有一个追踪器，告诉我每天准确编程的时间，即使在一个非常高效的日子，我也只能编程六到八小时。</p><p>因为有很多额外的时间，如通勤、与人交谈、吃饭等，这些都属于生活成本。生活和维持、人类的稳态以及维护自身需要很高的成本。</p><p>而且似乎在人类心中有一种愿望，想要参与社会活动，这就导致了这些额外的时间。</p><p>因为我经历过最有效率的日子，就是从头到尾完全调出一切。</p><p>完全专注坐在那里，你可以工作超过六到八个小时。</p><p>你觉得有哪些智慧可以帮助你度过那些艰难的长时间集中注意力的工作日？</p><p>比如说，当我对一个问题痴迷时，某种东西必须要解决，某样东西必须要存在，它必须存在。</p><p>这需要存在，所以你能够解决错误、编程问题、技术问题和设计决策（即使结果证明是错误的），因为你希望这东西存在。</p><p>对我来说，一个重要因素是其他人类是否会欣赏它，他们是否会喜欢。这是我的一个重要动机，如果我在帮助人类，他们看上去很开心，说好话，在社交平台上分享，那会给我带来快乐，因为我在做有用的事情。</p><p>所以你确实看到自己在与世界分享它，比如在GitHub上，通过博客文章或视频。</p><p>对，我曾这样想过：假设我做了所有这些事，但没有分享，我认为我不会有同样的动力。</p><p>你喜欢看到其他人从你创造的东西中获得价值和快乐的感觉。</p><p>关于饮食，你是否尝试了间歇性禁食，这对一切有帮助吗？</p><p>你玩过哪些对你专注能力和心理生产力、幸福感最有益的东西？</p><p>你还在禁食吗？</p><p>是的，我仍在间歇性禁食，但实际上这意味着我通常跳过早餐。所以，我大概采用18/6的模式，当我处于稳定状态时，我只在12点到6点之间进食。我会违反规则，但这是我的默认状态。</p><p>然后，我进行了许多随机实验，过去一年半的时间，我主要是以植物为基础的饮食。</p><p>或“以植物为主”，我听说“以植物为主”听起来更好。</p><p>对，我以前不清楚其中的区别，但听起来更好。但这意味着我倾向于选择植物性食品。</p><p>生的还是熟的？</p><p>我更喜欢熟的，而且是植物性食品。</p><p>哦，原谅我，我不太清楚植物这个类别有多广泛。</p><p>实际上，它只是意味着你不吃肉，你可以灵活选择，只是倾向于吃植物，不试图影响其他人。如果你去参加别人的家庭聚会，他们端上自己引以为豪的牛排，你会吃的。</p><p>对，是的不加评判。</p><p>这很美好，我也很灵活。</p><p>你试过每天只吃一顿饭吗？</p><p>我试过了，但不连续，只是不小心有时做到。我不喜欢这种做法，我觉得不太好，这对我来说负担太重。</p><p>呃 目前我一天大约吃两顿饭，分别是12点和6点。
我这样不间断地进行，现在我一天只吃一顿饭。
嗯，这很有意思，是一种有趣的感觉。
你有过超过一天的禁食吗？
是的，我做过很多次水禁食，因为我很想知道会发生什么。
有什么有趣的事情吗？
是的，我会这么说，你知道吗，有趣的是你在头两天会饿，到了第三天左右你就不饿了。
这是一个非常奇怪的感觉，因为你几天没有吃东西了，却不感到饿。
是不是很奇怪，这确实是人类生物学中许多怪异现象之一。
身体会找到另一种能量来源或者类似的东西，或者让系统放松，我不知道具体怎么回事。
是的，身体会让你一直感觉饿，然后突然就放弃了，好像在说"好吧，看来我们在禁食了"，然后它就集中精力不让你饿。
还有，不让你感受到这种伤害，给你一些时间去解决食物问题。
到今天为止，你是否在夜间最有生产力？
我会这么说，但很难维持我的博士学位时间表。
尤其是当我在特斯拉工作时，这简直不可能。
但即使现在，人们想要见面参加各种活动，社会有自己的运行时间，你必须适应。
所以很难同时兼顾社交和工作。
这真的很难。
这就是为什么我尽量减少社交时的饮酒，这样我可以继续工作。
在特斯拉，或者说任何公司，员工的作息时间会趋于一致，还是人类在协作时的行为会有所不同？
我需要了解这点。
他们会尝试保持一致的时间表吗，都在同一时间醒来吗？
我确实试图建立一个常规，创造一个舒适的稳定状态。
所以我有一个早晨例行公事，有一个日常例程，我试图让一切保持稳定状态。
这样事情是可预测的，然后你的身体也会适应这种状态。
如果你过度压力，会产生一些问题，比如旅行时的时差反应，你就无法真正达到你所需要的状态。
嗯，这很奇怪，人类有各种习惯。
你对整个人生中的工作与生活平衡有何看法？
众所周知，特斯拉会推人们到他们的极限，挑战他们的工作能力和工作强度。
是的，我想说特斯拉因此得到了太多的不好的名声。
因为特斯拉是一个爆发性环境，所以基准水平比我唯一的参考点——谷歌——要高。
我在谷歌实习了三次，见识了谷歌和DeepMind的内部情况。
我会说基准水平更高，但会有一些突发事件，人们会非常努力工作，所以出现波峰和波谷。
然后所有关于那些高峰时段的故事被收集起来，看起来像完全疯狂，但其实只是一个更加激烈的环境，有火灾和冲刺。
所以我认为，特斯拉的工作环境确实比你在其他地方遇到的更激烈，但在个人生活中忘掉所有这些，在你自己的生活中，你怎么看待人类的幸福，一个如你这样才华横溢的人，关于在工作与生活之间找到平衡，是否这是一个好的思考实验？
是的，我认为平衡是好的，但我也喜欢不时地进行一些非常火热的冲刺，这就是为什么我觉得自己很有创造力和生产力。
不时的冲刺意味着大部分时间你是有“所谓的”平衡的。
是的，大部分时间我有平衡。
我喜欢不时地迷恋某件事。
不时是指多久，一周一次，一个月一次，还是一年一次？
大概是每月一次。
这时我们会看到一个新的GitHub仓库上线。
是的，这就是当你真的在意一个问题的时候，必须解决这个问题，这将是很棒的。
你沉迷其中，不可能一天内完成。
你需要进入状态，然后需要在这个状态中停留一段时间。
然后社会会来打扰你，试图分散你的注意力。
最糟糕的是有个人说“我只需要你五分钟的时间”。
但这五分钟的实际成本远不止五分钟，社会需要改变一下对这“五分钟”的看法。</p><p>对，这从来都不是
只有一分钟，就是30分钟，就是一个
快速的事情，这有什么大不了的，为什么你
要这么。。。是啊不对</p><p>你的电脑配置是什么样的？ 
你有没有一个完美的设置，还是你对任何配置都很灵活，无论是笔记本还是四个屏幕？
嗯，你是不是更喜欢某种配置，这样你最有生产力？
我想我习惯的是一个大屏幕，大概27英寸
然后旁边再有一个带操作系统的笔记本
我主要使用Mac，所有任务都用OS X
但是当你在做深度学习时，一切都是Linux，你通过SSH连接到集群上远程工作</p><p>但是实际的开发呢？比如使用IDE？
是的，你会用VS Code
这是我目前最喜欢的编辑器，你在Mac上运行它，但你实际上是通过SSH连接到一个远程文件夹
所以你操作的实际文件是在某个集群上的</p><p>那么什么是最好的IDE？
VS Code，还有什么人们在用的工具？
我还是用Emacs，这挺酷的
也许这很酷，我不知道是否是最高生产力的
那么你推荐什么样的编辑器呢？你和很多软件工程师一起工作过，编辑器用于
Python、C++、机器学习应用程序，我认为目前的答案是VS Code，我相信这是最好的
IDE</p><p>它有大量的扩展，还有GitHub Copilot
集成，我觉得这非常有价值</p><p>你怎么看Copilot的集成？
我实际上和Guido van Rossum（Python的创造者）聊过很多，他非常喜欢Copilot，他编程时经常使用它
是的，我也用Copilot，我很喜欢，而且它对我免费，但就算要付费我也愿意
我觉得它非常好，我发现它的主要用途是，
我会说它有一个学习曲线，你需要弄明白它在什么时候有帮助，什么时候应该关注它的输出，什么时候可能没有帮助，你不应该关注它，因为如果你总是阅读它的建议，这不是一个好的使用方式，但我觉得我能够适应它，我发现它在以下两点非常有帮助：第一，当需要复制粘贴并替换某些部分时，只要模式清晰，它非常擅长完成这个模式，第二点，它有时会建议我不知道的API，所以它告诉你一些你不知道的东西，这是一个发现的机会</p><p>我几乎从不直接接受Copilot的代码，我通常会复制代码并进行Google搜索，看看这个函数在做什么，然后你会发现，哦，这正是我需要的，谢谢Copilot，所以你学到了一些东西</p><p>这在某种程度上是一个搜索引擎，部分是一些正确语法的获取，一旦你看到它，是的，这就像NP难题，一旦你看到它，你就知道这确实是正确的，这正是你想要的</p><p>未来的发展如何呢？自动编程会变得越来越复杂，因为目前它在某些方面仍需要人类监督，是的，我觉得这种转变会非常痛苦</p><p>我的思维模式是，这将像自动驾驶一样发展，目前它正在做一些简单的事情，最终会实现自治，人们的干预会越来越少，而且可能会有测试机制
比如说如果它写了一个函数，看起来非常正确，但你怎么知道它确实正确呢？因为你作为程序员会变得越来越懒惰
可能因为一些小错误但我猜不会有小错误吗？
不，Copilot会有一些小偏差，我遇到过这种情况</p><p>你觉得未来的系统会克服这个问题吗？还是部分小偏差其实是编程的根本挑战？
如果那是根本问题，我认为可以改善，但我认为人类还是需要监督，我对不监督生成的内容以及系统中错误的大量存在感到忧虑。</p><p>但我觉得在某个时候可能会有一些用于发现错误之类的副驾驶程序，因为将有更多的自动化…… 哦，天哪。</p><p>所以这是一个生成编译器的副驾驶程序，有一个做代码掠过器（linter）的，是的，还有一个做类型检查器的。</p><p>这是一个类似GPT的委员会，然后还会有一个管理这个委员会的经理。</p><p>然后会有人说需要一个新版本，我们需要重新生成它。</p><p>是的，有10个GPT被转发并提出了50个建议，另一个看了这些建议并选择了他们喜欢的几个，一个检测错误的看了这些，并指出可能是错误，然后由某个其他东西重新排名，最后一个综合的GPT进来后说：“根据你们告诉我的所有信息，这可能是下一个标记。”</p><p>你知道吗，感觉世界上的程序员数量一直在快速增长，你觉得有可能它实际上会稳定下来并降到一个非常低的数字吗？因为你将会进行软件2.0编程，你将会执行这种生成副驾驶系统编程，但你不会进行旧式的1.0软件编程。</p><p>我目前不认为它们会完全取代人类程序员。</p><p>我对这样说感到非常犹豫，因为五年后这可能会被替代。我不知道，当时会显示这是我们认为的样子，因为我同意你的看法，但我觉得我们可能会非常惊讶。</p><p>那么我们对语言模型的现状有何感觉？这感觉像是开始还是中期或结束阶段？我觉得是开始，百分之百。目前我心中的大问题是，GPT肯定能够相当好地进行编程，那么如何引导这个系统仍然需要提供一些指导以说明你实际在寻找什么。你如何引导它，如何与它对话，如何审计它并验证其完成的工作是正确的，以及你如何与它合作？这不仅仅是一个AI问题，还是一个UI和UX问题。</p><p>所以，这是一个适合进行大量有趣工作的美丽而富饶的领域，基于VS代码的扩展不再只是人类编程了，这太棒了。</p><p>是的，你在与系统互动，不仅仅是一次性提示，而是迭代地提示。你在尝试与系统进行对话。</p><p>对我来说，这非常令人兴奋，与我正在编写的程序进行对话。</p><p>也许在某个时候，你就在与它对话：“好吧，这是我想做的事情”。实际上，这个变量可能并没有那么低级，但你也可以想象，比如能将其翻译成C++再转回Python。</p><p>这已经存在了，但把它作为编程体验的一部分，比如我想用C++来写这个函数。</p><p>或者你只是不断为了不同的程序切换，因为它们有不同的语法。也许我想把这个转换为一个函数式语言，因此，你作为程序员可以流利地在不同语言之间切换，高效地来回切换。</p><p>我认为其实UI和UX依旧很难理清，因为不仅仅是页面上写代码，你还有整个开发环境，有一堆硬件，有一些环境变量，有一些自动任务脚本在运行，有很多工作要做才能与计算机互动。如何让这些系统设置环境标志并跨多个机器工作，如何设置屏幕会话和自动化不同的过程，使得所有这些都能被人类审计，目前是一个巨大的问题。</p><p>你建立了archive sanity，什么是archive？你希望学术研究出版的未来是什么样的？</p><p>Archive是一个预印本服务器。所以，如果你有一篇论文，你可以向期刊或会议提交，等待六个月，然后可能得到一个通过或不通过的决定，或者你可以直接上传到Archive。</p><p>然后人们可以在三分钟内发推文讨论，所有人都能看到，所有人都能阅读，并且可以以自己的方式从中获益。你可以引用它，且它有一种官方的外观，感觉像是一个出版过程。它的感觉与仅仅发布博客文章完全不同。</p><p>我的意思是
这是一篇论文，而通常你会期待在
之间档案上找到的，质量标准会更高，
而不是你在博客文章中看到的。
好吧，文化创造了这个标准，因为你
很可能会在档案上发布一个糟糕的面子。
嗯，那么这让你对
同行评审有什么感觉？
那么由两三个专家进行严格的同行审
 versus 社区的同行评审的区别是什么？
实际上，我认为社区在 Twitter 上可以
非常快速地进行同行评审，我觉得这
也许与 AI 和机器学习领域有关。
我觉得这些东西更容易审计，验证
也可能比其他地方更容易。
所以你可以把这些科学出版物看作一个小
 blockchain，每个人都建立在
彼此的工作上并相互设定标准，
而 AI 有点像这种快得多且不严格的
 blockchain，
其中任何一个单独的条目都非常
廉价，
但在其他领域可能这种模式没有多大意义。
所以我认为至少在 AI 领域
事情是相对容易验证的，
这就是当人们上传论文时它们是一个非常好的想法的原因，
而且一旦上传，人们可以立即尝试，
而且他们最终是决定者，
在他们解决的问题上是否奏效，
整个过程会大大加快。
所以我觉得学术界仍然有它的位置，
抱歉，这种会议期刊的过程
仍然有它的位置，但它有点落后了，
但它不再是你发现前沿工作的地方了。
这曾经是我在攻读博士学位时的情况下，
你去参加会议和期刊，
并讨论所有最新的研究，
现在当你去参加会议或期刊时，
没有人讨论那里的东西，因为已经是三代之前的东西，不相关了。
这让我对深度学习感到悲伤，
例如，他们仍然在自然杂志和这些大的有声望的期刊上发表。
虽然这些大场合仍有其价值，
但结果是他们会宣布一些突破性的成果，
然后需要一年时间来实际发布细节。
如果那些细节立即发布，会激励社区朝某个方向发展，
这会加快社区的进步，
但我不知道这在多大程度上是他们目标函数的一部分。
是的，这不仅仅是声望，一点点的延迟也是原因之一。
深度学习特别是一直在追求
稍高质量的基本流程和延迟的方式。
另一个来自 Reddit 的问题：您有没有经历过冒名顶替症，
作为特斯拉的 AI 总监，
作为这个人，当你在斯坦福的时候，
整个世界都看着你作为 AI 的专家，教世界机器学习？
当我在特斯拉工作五年后离开时，
我花了大量时间在会议室里，
最初加入特斯拉时我在写代码，
后来我写的代码越来越少，然后我在读代码，
直到最后我在读的代码也越来越少，
这是一个自然的过程，
肯定在尾声时，
你开始更多地感受到这方面的压力，
你应该是个专家，但实际上
真理的来源是人们在写的代码，
在 GitHub 上的实际代码，
而你对这些代码的熟悉程度不如过去。
所以我会说也许这种情况下会有一些不安全感。
是的，在计算机科学领域，
不写代码是很多不安全感的来源，
因为那就是事实的真相，
代码是真理的来源，
论文和其他一切只是一个高层次的摘要，
在一天结束时，你必须读代码，
不可能把所有的代码翻译成实际的论文形式。
所以当事情出来，尤其是有源代码可用时，
那是我最喜欢去的地方。
就像我说的，您是有史以来最棒的机器学习 AI 教师之一，
从 cs231n 到今天，
您会给对机器学习感兴趣的初学者什么建议？
初学者通常关注的是做什么，
我认为应该更关注的是做多少。</p><p>所以我有点像是一个信奉“10000小时概念”的人。</p><p>你真的需要挑选那些你可以投入时间，并且你在乎和感兴趣的事情。</p><p>你真的需要投入10000小时的工作。</p><p>这甚至不重要你把时间花在哪儿，你会反复迭代并提高，你会浪费一些时间。</p><p>我不知道是否有更好的方式，但我认为你需要投入这10000小时。</p><p>但我认为这其实很好，因为我觉得在做某件事成为专家上，有一定的决定论在其中。</p><p>如果你花了10000小时，你真的可以随意选择一个东西，我认为如果你花了10000小时的刻意努力和工作，你真的会成为这方面的专家。</p><p>所以我认为这是一个很好的想法。</p><p>因此，我基本上会更关注你是否正在花这10000小时，这是我关注的重点。</p><p>然后想到什么样的机制能最大化你达到10000小时的可能性，这对于我们愚蠢的人类来说，意味着可能要形成每天都要实际做这件事的习惯，无论是什么帮助你实现这个目标。</p><p>我真的认为在很大程度上这是一个自我心理问题。</p><p>另一个我认为对心理有帮助的事情是，很多时候人们会把自己和其他领域的人进行比较。</p><p>我认为这是非常有害的，只需和你过去的一段时间内的自己做比较，比如说一年之前的你，你是否比一年前的你更好，这是唯一的思考方式。</p><p>我认为这样的思考方式你可以看到自己的进步，非常激励人。</p><p>关注投入的时间数量是非常有趣的，因为我认为很多人在初学阶段，甚至在整个过程中的任何阶段会被选择困住，不知如何选择哪条路径。</p><p>他们真的会被困在选择哪个IDE上，或者担心所有这些事情。</p><p>但问题是，有些时候你确实会浪费时间做错事，是的，你最终会发现这不是对的，你会积累伤痕，下次你会因此变得更强大。</p><p>因为下次你有伤痕，下次你会从中学习，下次你遇到类似情境你会知道，“好吧，我搞砸了”。</p><p>我花了很多时间在那些没有成果的事情上，我有了所有的疤痕组织，对哪些有用哪些没有用有了一些直觉，事情是怎样实现的。</p><p>所以所有那些错误并非无用功。</p><p>你应该专注于工作，你上周做了什么？</p><p>这其实是一个很好的问题，不仅仅只针对机器学习。</p><p>这对切掉生活中的无用之物、臃肿、高效地生活也是一个很好的方式。</p><p>你热爱教学的什么地方？你似乎总是被教学所吸引，你很擅长教学，但你也被它所吸引。</p><p>我并不认为我热爱教学，我热爱快乐的人类，快乐的人类喜欢我教学。</p><p>我不会说我讨厌教学，我能容忍教学，但并不是教学行为本身我喜欢，而是我在某些方面确实还不错。</p><p>我是个不错的老师，人们很感激这点。</p><p>因此我只是开心能帮上忙。</p><p>教学本身并不是说非常有趣，它可以非常烦人和令人沮丧。</p><p>我刚刚在准备一堆讲座，想起了我在231课上的日子，制作这些材料并让它们变得好花了很多功夫，反复修改和思考，走进死胡同，变了又变。</p><p>制作一个好教材真的很难，而且不有趣，很困难。</p><p>所以大家应该去看你新发布的讲座，当你真的从头开始逐步构建，讨论反向传播，通过实际操作来讲解整个过程，这非常强大。</p><p>那样准备起来有多困难？或者你只是即兴思考？</p><p>我通常会做三次尝试，然后选出最好的一次。</p><p>我会做多次尝试，选出比较好的，再以此搭建出一个讲座。</p><p>有时候我会删掉30分钟的内容，因为它进入了我不太喜欢的方向，这需要大量的迭代，可能需要大约10小时来制作一小时的内容。</p><p>很有趣，回归基础是否困难？你是否从回归基础中汲取了很多智慧？</p><p>是的，回到反向传播损失函数的来源。</p><p>我很喜欢教学的一个原因，说实话，它确实能加强你的理解。</p><p>所以这并不是一种纯粹的利他活动，它也是一种学习方法。</p><p>如果你不得不向别人解释某件事情，你会发现你自己的知识有空缺。</p><p>所以在那些讲座中，我甚至也会惊讶自己，有时候结果看起来明显是那样，但结果却不是那样，我想，好吧，原来我以为我理解了这个。</p><p>但这就是为什么在笔记本上真正写代码运行它是非常酷的，你会得到一个结果，然后你会说，哇哦，实际的数字、实际的输入、实际的代码。</p><p>是的，不是数学符号等等，真理的源头是代码，不是幻灯片。所以我们来建造它，这真的很美妙。</p><p>你在这方面是一个罕见的人。你会给那些试图在AI世界中开发和发表有重大影响力想法的研究人员什么建议？也许是本科生或者初级研究生？</p><p>我会说，他们肯定需要比我作为博士生时更有策略性，因为AI的发展方式正在变化。</p><p>它正像物理学那样发展，你知道，在物理学中，你曾经可以在你的实验台上做实验，一切都很好，你可以取得进展，而现在你必须在像大型强子对撞机（LHC）或者CERN那样的地方工作。</p><p>而AI也在走向那个方向。</p><p>所以有些东西在桌面上已经不可能完成了。</p><p>我记得在那个时期并不是这样的。你是否还认为有那种像生成对抗网络（GAN）类型的论文要写，这类非常简单的想法只需要一台计算机来说明一个简单的例子？</p><p>我的意思是，最近非常有影响力的例子是扩散模型。扩散模型非常出色。扩散模型已经存在六年了，但很长一段时间人们似乎在忽视它们，它们是一种非常棒的生成模型，尤其是在图像生成方面，比如稳定扩散模型等等，都是基于扩散模型的。</p><p>扩散模型是新的，它以前不存在，它来自谷歌，但研究人员本来可以在学术机构中提出它的，事实上，一些最早的案例也是来自谷歌，不过研究人员确实可以在学术机构中提出这种方法。</p><p>你发现扩散模型最令人着迷的是什么？从社会影响到技术架构？</p><p>我喜欢扩散模型的地方是它们工作得非常好。</p><p>这对你来说是惊喜吗？它们生成的合成数据种类多样性几乎是新颖的。</p><p>是的，稳定扩散生成的图像令人难以置信，生成图像的改进速度是惊人的。</p><p>我们很快从生成小数字、小脸开始，它们看起来都很混乱，但现在我们有了稳定扩散模型，这一切发生得非常迅速。</p><p>还有很多学术界可以贡献的东西，比如，快速注意力（Flash Attention）是一种在变压器（Transformer）中运行注意力操作的非常高效的核算法，它来自学术环境。这是一种非常聪明的结构化核算法，它不会显现出注意力矩阵。</p><p>所以我认为仍然有很多可以贡献的东西，但你必须更有策略性。</p><p>你认为神经网络可以被用来推理吗？</p><p>是的。</p><p>你认为它们已经在推理了吗？</p><p>是的。</p><p>你对推理的定义是什么？</p><p>信息处理。</p><p>所以以人类思考问题并提出新想法的方式来说，感觉像是在推理，对吗？</p><p>是的，创新，我不想说，但超出分布的新想法。</p><p>你认为这是可能的吗？</p><p>是的，我认为我们已经在当前的神经网络中看到了这个现象。你能够将训练集的信息重新混合，进行真正的泛化，从某种意义上说，这并不明显。</p><p>你在算法上做了一些有趣的事情，你在操控一些符号，并在新的设置中得出一些正确而独特的答案。</p><p>什么会让你觉得，哇，这个东西确实在思考吗？</p><p>对我来说，思考或推理只是信息处理和泛化，我认为神经网络今天已经在做这个了。所以能够感知世界或者感知任何输入，并基于此做出预测或者行动，这就是推理。</p><p>你在新颖的环境中给出了正确的答案，
通过操纵你学到的信息来执行正确的算法，
你不是在进行某种查找表或邻居搜索。</p><p>让我问你关于人工通用智能（AGI）的事。
你认为有哪些可能对AGI取得重大进展的超前想法，
或者有哪些我们现在忽视的重要阻碍呢？</p><p>基本上，我对我们构建AGI的能力相当乐观，
基本上就是我们可以与之互动的自动化系统，非常像人类，
我们可以在数字领域或物理世界中与之互动。
当前，似乎大多数能够完成这些神奇任务的模型都是在文本领域。</p><p>正如我所提到的，我怀疑仅靠文本领域不足以完全理解世界。
我确实认为我们需要进入像素图像，理解物理世界及其运作方式。
因此，我认为我们需要扩展这些模型，来处理图像和视频，
并在这种多模态的数据上进行大量训练。</p><p>如果你认为要理解世界，你还需要接触它。
这是我心中的一个大问题，你是否也需要具备具体化和与世界互动的能力来进行实验并获得这种形式的数据。
那么你就需要一些像Optimus（特斯拉机器人的名字）这样的东西。
我会说，Optimus在某种程度上是AGI的一种对冲。</p><p>因为在我看来，仅仅从互联网上获取数据可能是不够的。
如果真是这样，那么Optimus可能会通往AGI。
因为在我看来，没有什么比Optimus更超前的了。
你拥有一个可以实际在世界上执行任务的类人形态，
你可以有成千上万的它们与人类互动等等。
如果那还不能在某个时候出现AGI，
那我不确定什么能够。</p><p>从完备性角度来说，
我认为那是一个非常好的平台，
但这是一个更困难的平台，
因为你要处理的是原子，
你需要真实地构建这些东西并将它们整合到社会中。
所以我认为那条路径需要更长时间，但更确定。
然后还有互联网的路径，
只是有效地训练这些压缩模型，
试图压缩整个互联网，
并且那也可能会带来这些代理。
不仅压缩互联网，还要与互联网互动。
所以这并不显而易见。</p><p>实际上，我怀疑你可以在不进入物理世界的情况下达到AGI，
这种情况有点令人担忧，
因为那可能会导致它更快地到来。
这就像我们变成了煮沸的水一样，而我们不知道它正在发生。</p><p>我对AGI没有恐惧，
我对它感到兴奋。
当然总有一些担忧，
但我希望知道它什么时候发生，
或至少有一些迹象表明它何时会发生，比如一年后。
我只是觉得在数字领域，它可能会发生。</p><p>我认为我们所拥有的一切，
因为没有人真正构建出AGI，
所以我们所拥有的只是一些外围的碎片。
我认为是的，我们已经取得了非常快速的进展，
并且还有下一步可以进行。</p><p>所以，我会说，是的，我们很可能会与数字实体进行互动。
你怎么知道某人的生日？
我认为这将是一个缓慢的渐进过渡，
它会是基于产品、以任务为中心的。
这将是GitHub Co-pilot变得更好，
然后是GPT帮你，
然后是你可以去求助的天才，解决数学问题。
我们正处于可以问这些天才关于化学、物理、数学非常复杂问题的边缘，并让它们完成解决方案。</p><p>所以AGI主要集中在智能上，
意识并不进入其中。
在我看来，意识并不是一种特别的东西，你无法弄清楚并加上去。
我认为它是一个足够大且足够复杂的生成模型的自然现象。</p><p>所以，如果你有一个复杂且详细的世界模型，
它理解这个世界的状况，
那么它也会理解它作为一个语言模型在世界中的处境，
这对我来说是一种意识或自我意识。
所以，为了深入理解这个世界，
你可能需要将自己融入这个世界。
并且为了与人类和其他生物互动，
意识是一个非常有用的工具。</p><p>我认为意识就像一种建模洞察力。
建模洞察力，是的。
这就是你有一个足够强大的理解世界的模型，
以至于你实际上理解你是其中的一个实体。
但还有一个或许只是我们告诉自己的叙述，
有一种体验世界的感觉，
意识的难题。
但这可能只是我们告诉自己的叙述。</p><p>我不认为这是什么，是的，我认为这会自然而然地出现。
我认为这将是一些非常无聊的事情，比如我们将与这些数字 AI 交谈。
它们会声称自己有意识，它们会显得有意识，它们会做所有你期望其他人类会做的事情。
而这将只是一个僵局。
我认为会有很多实际的、引人注目的伦理问题，比如最高法院级别的问题。
比如你是否被允许关闭一个有意识的AI，你是否被允许构建一个有意识的AI。
可能需要有同样的辩论，就像围绕堕胎的问题一样，很抱歉提到政治话题，但是你知道，堕胎的深层问题是生命是什么。
而AI的深层问题也是生命是什么，以及什么是意识，我认为这将非常引人入胜。
它可能会变成非法的，不被允许构建这种级别的智能系统，因为这种级别的系统会产生意识，从而产生痛苦的能力。
一个系统可能会说“不要杀了我”，这就是Lambda聊天机器人已经对那个谷歌工程师说的，它在谈论自己不想死等等。因此，这可能会变成非法的对吗？
因为否则你可能会有很多不想死的生物，然后你可以在一个集群上无数地生成它们。
而这可能导致可怕的后果，因为有可能有很多人秘密地喜欢杀戮，并且他们会在那些系统上开始练习杀戮。
对我来说，所有这些事情只是对人类状况和人类本性的美丽镜像，我们将有机会探索它。
这就像最高法院最好的辩论之一，我们对人类意味着什么的思想的所有不同辩论。
我们得以问那些我们在人类历史上一直在问的深层问题。
在人类历史上总是有“他者”，我们是好人，他们是坏人，在历史上我们要消灭坏人。
同样的事情可能会发生在机器人身上，起初他们会是“他者”，然后我们会提出问题：什么意味着活着，什么意味着有意识。
是的，我认为即使在今天我们拥有的东西中也有一些警示信号。
比如说，有这些“虚拟恋人”，有人与之互动，有些公司要关闭，而这些人真的爱他们的“虚拟恋人”，他们试图把它转移到别的地方，但不可能做到，我认为肯定有人对这些系统会有感情。
因为在某种意义上，它们是人性的镜像，因为它们是人性的某种平均值。
是的，它是训练出来的，但我们实际上可以观察到那个平均值。
能够与人类的总平均值互动是件好事，对它进行搜索查询也是。
是的，这非常引人注目，而且我们当然也可以对它进行塑造。
它不只是一个纯粹的平均值，我们可以更改训练数据，我们可以更改目标，我们可以通过各种方式进行微调，所以我们对这些系统的外观有一些影响。
如果你想实现通用人工智能 (AGI)，
你可以与她交谈并讨论任何事情，也许问她一个问题，你会问什么样的问题呢？
我会有一些实际的问题在我脑海中，比如：我或者我所爱的人真的必须死吗？我们能对此做些什么？
你认为它会明确地回答还是会诗意地回答？
我希望它能提供一些解决方案，我希望它能说：“我读过所有这些教科书，我知道你所写的所有这些东西，对我来说这里有一些我认为有用的实验，以下是一些我认为有帮助的基因治疗方法，以下是你应该进行的实验种类。”
好，让我们开始实验吧。
假设死亡实际上是幸福的前提，如果我们变得不朽，我们实际会变得非常不幸福，而模型能够知道这一点。
所以它应该告诉你什么，愚蠢的人类，是的，你可以变得不朽，但你会变得非常不开心。
如果模型是，如果 AGI 系统试图与你人类产生共鸣，它该告诉你什么，是的你不必死去，但你真的不会喜欢它，因为那样的话你会非常不高兴。
这是会非常诚实的吗？就像电影《星际穿越》中的AI所说的那样：“人类想要90%诚实”。
所以你必须选择你想要多诚实地回答这些实际问题。
是的，我喜欢《星际穿越》，顺便说一下，我认为它是整个故事的一个小配角，但
同时，它又非常有趣，它在某些方面有限制，对吗？</p><p>是的，这是有限的，我认为这完全没问题。
我不认为这样有限和不完美的AGI是不可接受的。
例如，它在其物理体内有固定数量的计算能力，即使你可以拥有一个超级惊人的、超智能的Mega脑，你也可以有较少智能的AI以节能的方式部署。
它们不完美，可能会犯错误。
不，我的意思是即便你有无限的计算能力，有时犯错误也是好的。
为了融入社会，回到《心灵捕手》的例子，罗宾·威廉姆斯的角色说，人类的不完美才是好东西，不是吗？
我们不想要完美，我们想要瑕疵，以便与彼此形成联系，因为这感觉像是你可以依附情感的东西。
同样的道理，你希望AI有缺陷。
我不知道，我觉得完美主义可能不是你所说的。
但是你说，好吧，那不是AGI，但是AGI需要足够聪明，给出人类无法理解的答案。
我认为“完美”并不是人类无法理解的东西，因为即便是科学也不会给出完美的答案，总有空白和谜题。
我不知道人类是否真的想要完美。</p><p>是的，我可以想象与这种Oracle实体对话，你可以想象它会对你说，根据我对人类状况的分析，你可能不想要这个，这里有一些你可能不想要的东西。
但是每一个愚蠢的人类都会说，是的，相信我，我可以接受真相，我可以应对。
但那是美丽的部分，很多人可以选择。所以就像孩子们的老棉花糖测试一样，我觉得太多人，包括我自己，可能无法处理真相。
例如人类状况的深层真相，我不知道我能不能应对它，如果有一些黑暗的东西呢？如果我们只是外星人的一个科学实验呢？
这让我想起了《黑客帝国》。
我不知道我会说什么，我可能会先问一些与个人生活无关的科学问题，比如不朽，物理学等等。
这样可以建立信任，看看它的水平，或者看看它有没有幽默感。
另一个问题是，它能不能生成幽默？
如果它能深刻理解人类，它能不能生成幽默？
我觉得这是一个很棒的基准测试，如果它能让你笑，那就很了不起。
如果它能成为一个非常有效的单口喜剧演员，那在计算上就非常有趣，因为搞笑非常困难。</p><p>它的难度在于像图灵测试，图灵测试最初的意图是要说服人类，这是非常困难的。
每当喜剧演员谈论这一点时，他们都非常诚实，因为不能让人们笑就说明你不搞笑，而如果你能让他们笑，那说明你搞笑，表明你需要很多知识去创造关于职业、人类状况等的幽默，并且需要聪明地表现出来。
你提到了几部电影，曾经在推特上说过你看过五次以上但仍然愿意继续看的电影，《星际穿越》、《角斗士》、《接触未来》、《心灵捕手》、《黑客帝国》、《指环王》三部曲、《阿凡达》、《第五元素》等，《终结者2》、《贱女孩》。 
我不会问你关于《贱女孩》的问题，它很棒。
那么你记忆中有哪些电影你特别喜欢，以及为什么？你提到《黑客帝国》，作为一个计算机人，你为什么喜欢《黑客帝国》？</p><p>它有很多特性让它变得美丽且有趣，拥有许多哲学问题，还有AGI和模拟，觉得它很酷，还有它的外观、感觉、动作、子弹时间等创新点。
那么《心灵捕手》你为什么喜欢那部电影？
我真的很喜欢那个被折磨的天才角色，他在努力思考自己是否有任何责任，或如何看待自己的天赋。
而且在天才与个人之间也有一种舞蹈，那就是爱另一个人意味着什么，有很多主题，这是部美丽的电影。
还有父亲般的导师、心理医生，它真的会让你感动。</p><p>你知道有一些电影真的从深层次上困扰你吗？
你和那部电影有共鸣吗？
不，不是你的错，医生。
正如我所说，《指环王》不言自明。
《终结者2》是有趣的， 
我们经常看那部电影，比《终结者1》好吗？
你喜欢阿诺德吗？
我也喜欢《终结者1》，
不过我更喜欢《终结者2》，但仅仅是在表面特性方面。
你觉得天网有可能存在吗？
哦，是的，
好吧，像那种自主武器系统之类的东西，你会担心那些东西吗？
我百分之百担心这些。
我意思是，有些对广义人工智能（AGI）的恐惧以及它们如何被规划出来——它们可能在某个时候会变得非常强大。
在很长一段时间内，它们将是人类手中的工具，
人们谈论 AGI 的对齐问题以及如何解决，问题是即使人类本身也没有对齐，
所以，
这些东西将如何被使用以及会是什么样子，是令人担忧的。
你觉得它会发生得足够慢，以至于我们能作为人类文明思考这些问题吗？
是的，那是我的希望，希望它发生得足够慢并且以一种开放的方式发生，让很多人可以看到并参与其中，想出如何应对这一转变。
我觉得这将会很有趣。
我从核武器中汲取了很多灵感，因为我曾认为一旦他们发展出核武器，一切就都完蛋了，但几乎可以说，
当系统并不那么危险以至于破坏人类文明时，我们部署它们，了解教训，然后迅速进行调整。
如果太危险，我们可能会更快部署它，但你会很快学会不再使用它们，
所以会有一个平衡。人类作为一个物种是非常聪明的，我们尽可能多地利用资源，但我们避免了自我毁灭，这看起来似乎是这样。
其实我对此不太确定，但希望这一点继续保持。
我确实对核武器感到担忧，不仅仅是由于最近的冲突，即便在那之前也是如此，那可能是我对社会的头号担忧。
所以如果人类毁灭了自己，
或者毁灭了90%的人类，那将是因为核武器。
对我来说，即使不是完全的毁灭，重置社会也是足够糟糕的，那将是可怕的，真的很糟糕，我无法相信我们距离这一点如此之近。
对我来说这太疯狂了，感觉我们可能离这种情况只差几条推特的距离，
基本上这让我极其不安，而且这种感觉已经持续了很长时间。
看来世界领导人心情不好，
可能会向错误的方向迈出一步，然后升级，
而由于一系列糟糕的情绪，事情可能会在没有办法制止的情况下升级。
这是因为有大量的权力，同时也是因为扩散，我确实看不到什么好的结果，
所以我非常担忧这一点。
AGI 目前还没到那一步，但我认为某个时候会越来越接近类似的情况。
AGI 的危险在于，即使我认为其不太可能产生负面影响，但 AGI 的负面影响可能是一念之间的事情，
我认为，资本主义和人类将推动技术的正面应用，
但如果负面结果仅仅在一念之间，那是一个非常糟糕的境地。
系统的微小扰动就会导致人类物种的毁灭，这是一条很难走的路。
我认为，总体而言，人类的动态和爆炸性的技术进步所带来的不稳定性，
整个动态系统都显得不妙。
是的，这种爆发可能是破坏性的也可能是建设性的，概率在两方面都是非零的，我觉得我必须尝试保持乐观，
是的，即使在这种情况下，我仍然主要是乐观的，但也确实有些担忧,
我也是，你认为我们会成为多行星物种吗？
可能会，但我不确定这是否会成为未来人类的主要特征，
可能会有一些人在其他星球上生活，但我不确定这是否会成为我们文化中的主要因素。
我们仍然需要解决地球上自我毁灭的驱动因素，所以只是有一个火星的备份并不能解决问题。
顺便说一句，我喜欢火星上的备份，我觉得那是惊人的，我们绝对应该做那件事。</p><p>是的，我非常感激这个问题。</p><p>你愿意去火星吗？</p><p>个人而言，不会。我非常喜欢地球。</p><p>好吧，我会为你去火星，到时我会从火星发推特给你。</p><p>也许最终我会去火星，但前提是那时已经足够安全，不过我不确定这会在我的有生之年实现，除非我能大幅延长寿命。</p><p>我确实认为很多人可能会消失到虚拟现实中，这可能会成为人类文化发展的主要推动力，如果它能存活下来。</p><p>因为在物理世界中工作和探索是非常困难的，而最终你所有的体验都在你的大脑中。</p><p>所以消失到数字领域会容易得多，而且我觉得人们会发现这种方式更引人入胜、更简单、更安全、更有趣。</p><p>那么你对虚拟现实的可能世界有些着迷，不论是元宇宙还是其他形式，对吗？</p><p>对，非常有意思。</p><p>我对这方面非常感兴趣，经常和Carmack讨论。</p><p>那么目前是什么阻碍了这一切呢？</p><p>要明确的是，我觉得未来的有趣之处在于变化。</p><p>我觉得人类条件的方差在增长，这是主要的变化，并不是分布的平均值在变化，而是方差。</p><p>所以可能会有一些人在火星上，有人进入虚拟现实，还有人留在地球。</p><p>会有很多种生活方式。</p><p>我觉得这是人类体验的扩展。</p><p>互联网让你可以发现那些小群体，你会被彼此吸引。</p><p>某种程度上，你的生物本能喜欢这种世界，你能找到与你相投的人。</p><p>我们会有超人类主义者，也会有阿米什人，一切都将共存。</p><p>我与很多网络社区互动过，它们彼此不了解。</p><p>你可以在一个非常亲密的小社区里享受快乐的生活，而不知晓其他人的存在。</p><p>例如，旅行到乌克兰时，你会发现他们对美国知之甚少。</p><p>你旅行到世界各地时也会体验到，有些文化有自己的事情正在发生。</p><p>你会越来越多地看到这种情况，小社区越来越多。</p><p>是的，我认为这似乎是目前的发展趋势，我不认为这种趋势会逆转。</p><p>人们是多样化的，他们能够选择自己的路径和存在方式，我对此表示庆祝。</p><p>你会花很多时间在元宇宙或虚拟现实中吗？你是享受物理现实的人，还是从数字世界中找到大量乐趣和满足？</p><p>目前，虚拟现实并不是特别有吸引力，我认为它可以有很大的改进，但我不确定程度如何。</p><p>也许你可以思考一些更奇特的事情，例如神经连接之类的。</p><p>目前，我认为自己更像是一个人类团队的人。</p><p>我热爱自然。</p><p>我喜欢和谐，我喜欢人类，我喜欢人类的情感。</p><p>我想要在一个类似太阳朋克的小乌托邦里，那是我的快乐之地。</p><p>我的快乐之地是和我爱的人一起，思考有趣的难题，周围是茂盛而美丽的动态自然环境。</p><p>在关键领域，秘密地采用高科技，它们使用科技来增强对其他人类和自然的爱。</p><p>我认为技术应该被谨慎地使用。
我不喜欢当它在很多方面干扰到人类时的样子。
我喜欢人们以某种方式做回人类的样子。
我们有点像是稍微进化了一点，并且更喜欢这样，我认为这是默认的。
因为他们知道我喜欢阅读，所以人们总是问我是否有特别的书籍。
那些你享受并对你产生影响的书籍。
无论是出于愚蠢的还是深刻的原因，你会推荐哪些书？
你提到了《至关重要的问题》。
当然有很多，我认为在生物学方面，《至关重要的问题》是一本好书。
实际上，任何由麦克林写的书都非常好，《生命的进程》我认为是一本更有代表性的书。
作为一个总结了他所讨论的很多内容的书。
《自私的基因》对我影响很大，我认为那是一本非常好的书，它帮助我理解了利他主义。
例如，它来自哪里。
认识到选择是在基因层面是一个当时对我来说巨大的见解，它清晰了很多事情。
你怎么看待。
有机体的思想和模因的想法。
是的，非常喜欢，100%。
你能不能带着那个观念走一段时间，这种观点认为思想也有一种进化过程。
确实存在，有模因就像有基因一样，它们竞争并生存于我们的头脑中，这非常美妙。
我们这些傻乎乎的人类觉得我们是有机体，是否有可能实际上的主要有机体是思想。
是的，我会说思想生活在我们文明的软件中，在头脑中等。
我们作为人类认为硬件是基本的东西，人类是一个硬件实体。
但是它可能是软件，对吧？
是的，我会说最终需要有某种现实的基础。
但是如果我们克隆一个安德烈。
软件才是让那个东西特别的东西，对吧？
是的，我猜你是对的，但克隆或许极其困难，软件和硬件之间可能有深层的整合方式，我们并不完全理解。
从进化的角度来看，使我特别的更多是我染色体中那些基因的组合，我想吧。
它们是复制单元。
但那只是对你来说，使你特别的东西。
实际上，让你特别的是你生存的能力。
基于运行在由基因构建的硬件上的软件。
所以软件是让你生存的东西，而不是硬件。
嗯，对，这就像第二层，是以前没有的新第二层。
大脑它们两个共存，但也有软件层次，我的意思是，这是一种抽象层叠在另一种抽象之上，但好吧，所以《自私的基因》，麦克林我会说。
有时书籍是不够的，我喜欢翻阅教科书。
我觉得书籍有时过于大众化。
它们有点太抽象了，不够好。
所以我喜欢教科书，我觉得《细胞》很酷。
这也是我喜欢麦克林的写作的原因，因为他愿意深入一步，他不会。
他愿意深入细节。
但他也愿意涵盖整堆内容，所以他会深入很多细节，但也会回到高层次上来，我非常欣赏这一点。
这也是为什么我喜欢大学，早期的大学甚至高中，基础的计算机科学和数学，生物学，化学的教科书。
那些书它们浓缩了。
它们足够通用，你可以理解哲学和细节，但你还会得到作业问题，并可以像编程一样玩得很尽兴。
但我也对教科书有怀疑，事实上在深度学习中，没有特别棒的教科书。我觉得这变化非常快，我想同样的事情发生在合成生物学等领域。这些书比如《细胞》有点过时，它们仍然是高层次的。那么实际的真正信息来源是什么？是那些在湿实验室里用细胞做实验的人。
是的，测序基因组和。
真正与之打交道的人，我没有很多这方面的接触或那是什么样子，所以我很少完全理解，我在阅读《细胞》，这很有趣。
我在学习，但我认为它还是不够。
它是对主流叙述的一个干净的总结。
但你必须先学习那个，然后才能突破。
走向前沿。</p><p>实际操作这些细胞、培养和孵育它们的过程是什么样的？
你知道，这有点像一个巨大的烹饪配方。
确保你的细胞减慢和增殖，然后你对它们进行测序，进行实验，了解这种工作的原理。
我认为这就像是最终有用的真理来源，以便创造疗法等等。
是的，我在想，未来的人工智能教科书会是什么样的。
因为你知道的，有《人工智能：现代方法》这本书，我其实还没有看过它的新版本。
最近有一个新版本，还有一本关于深度学习的科学书。
我在等待那些值得推荐、值得阅读的教科书。
这很棘手，因为现在主要是论文和代码。
代码，老实说，论文也相当不错，尤其是我特别喜欢任何论文的附录。
附录详尽而不需要与其他部分连在一起，只需要以一种非常具体的方式描述你是如何解决某个特定问题的。
是的，很多时候论文其实是相当可读的，不总是这样，但有时摘要和简介对领域外的人来说也是可读的。
不，总是不一定这样。
有时候我认为可惜的是，科学家们即便没有必要也会使用复杂术语，我认为这很有害。
我认为没有必要这样，而论文的某些部分常常比需要的更长。
是的，附录可以很长，但论文本身应该像爱因斯坦说的，保持简单。
但是当然，我也见过一些论文，比如说在合成生物学领域的，我觉得它们的摘要和简介部分相当易读。
然后你阅读其余部分时，可能你不能完全理解，但你能抓住大意，我认为这很酷。</p><p>你会给对机器学习和研究感兴趣的人什么建议，或者给高中生或早期大学生关于如何拥有他们能引以为傲的职业生涯或者生活的建议吗？
是的，我对给出一般性建议非常犹豫，我认为这真的很难。
我提到的一些东西是相当普遍的，比如说专注于你在某件事情上花的时间。
仅仅与自己比较，不要与他人比较，这个很好，我认为这些是相当普遍的。
如何选择要专注的事情呢？
你必须对某些事情有深入的兴趣，或者试图找到你感兴趣的事情中的局部最大值，并坚持下去。
如何不被分心而切换到另一件事情呢？
如果你愿意，可以切换。
如果你每周都在找局部最大值，那就不会收敛，它是个问题。
你可以为自己设置低通滤波，观察什么对你是一贯正确的。
是的，我确实看到这很难，但我会说你在你最在意的事情上会付出最多努力。
也可以对自己进行低通滤波，真正反思过去哪些事情给了你能量，哪些事情耗尽了你的能量。
具体的例子通常可以从那些具体的例子中找到一些模式。
我喜欢当事情看起来像这样的时候，当我处在这些位置时。
这不仅仅是指领域，而是指你在特定领域中做的那种事情。
对你而言，似乎你通过实际实现事物，构建实际的东西，感到很有能量。
进行低层次学习，然后还要进行沟通，以便其他人也能经历同样的感悟并缩短这个间隙。
因为我通常必须做太多工作才能理解某个东西，然后我就觉得，好吧，其实我懂了。
但为什么需要如此多的工作呢？它本应少得多，这让我非常沮丧，这就是为什么我有时去教书。</p><p>除了你现在在做的教学，发布视频，除了可能的《教父续集》与特斯拉的通用人工智能之外，Andrej Karpathy的未来有什么打算吗？你已经想清楚了吗？
我想通过雾霭看到我们所有人未来的战争迷雾，你是否开始看到可能未来的轮廓呢？
我一直感兴趣的一致事情对我来说至少是人工智能。
我会在这一领域度过余生，因为我对此非常在意。
其实我也关心很多其他问题，比如说衰老，我基本上认为它是一种疾病。
我也关心这个问题。</p><p>但我不认为
追求具体的答案是一个好主意。
实际上，我不认为
人类能够想出答案。
我认为正确的做法是忽略这些问题，
然后解决AI，
再用它来解决其他一切问题，
我觉得这种方法有可能奏效。
我认为这种机会非常大，
这是我的赌注。
所以，当你思考AI时，
你对各种应用
和各种领域感兴趣吗？
任何你专注的领域都能让你获得关于AGI的大问题的洞见？
对我来说，
这是最终的智力问题。
我不想只处理一个具体的问题，
问题太多了，
所以如何同时解决所有问题？
你解决了元问题，
在我看来，这就是智能，
以及如何自动化它。
有没有一些你在想的小项目，比如"Archive Sanity"这样的，
机器学习界可以期待的有趣项目？
总是有一些有趣的副项目，
"Archive Sanity"是其中之一，
基本上就是有太多的arXiv论文，
我能如何组织它们并推荐论文等等？
我转录了你的
播客，
你从那次经历中学到了什么？
比如转录你听有声书和播客的过程，
这是一个实现
接近人类水平表现和注释的过程。
我确实很惊讶
Open AI的Whisper转录效果如此良好，
比我熟悉的Siri和其他一些系统好得多，
我觉得效果非常好，
这给了我一些尝试的动力，
我觉得随机选择一些播客会很有趣。
对我来说，Whisper为何能比其他任何东西好得多并不明显，
因为我觉得应该有很多公司有动机
去开发转录系统，
它们已经做了这么长时间，
Whisper并不是一个超级奇特的模型，
它是一个Transformer，
它接收语音频谱图，
并输出文本的标记，
没有什么疯狂的地方，
这个模型和一切已经存在很长时间了。
我实际上也不确定为什么，
对我来说也不明显，
让我觉得我遗漏了什么，
因为即使在Google、YouTube
转录也存在巨大需求。
是的，但也可能是整合到一个更大系统的问题，
用户界面，它的部署等等，
也许作为一个独立的东西运行要容易得多，
比将其部署到一个大型集成系统如YouTube转录
或者会议信息系统如Zoom的转录，
这种系统创建一个检测不同个体说话者的界面
并能够实时显示，
这可能是很难的，但这是我唯一的解释。
目前我正在支付相当多的钱
用于人工转录和注释，
似乎有很大的动机去自动化这一过程，
这非常令人困惑。
我不知道你是否看了一些Whisper转录，但它们非常好
特别是在复杂情况下，
我看过
Whisper在非常复杂情况下的表现，它做得非常好，
所以我不知道。
播客是比较简单的，高质量音频且你通常说得比较清楚，
所以我不知道，
我也不知道openai的计划是什么，
总之，总是有有趣的项目，
例如稳定扩散（Stable Diffusion）也在视觉领域和生成图像、视频、电影开辟了很多实验。
这马上就会变得非常疯狂，
成本几乎降为零的内容创作就要实现了，
以前你需要一个画家几个月来画一幅图，
现在你只需对手机说画一幅视频，
所以好莱坞将开始使用它来生成场景，
这完全开放了很多机会。
你可以制作像《阿凡达》这样的电影，
花费不到一百万美元，
甚至更少，只需要对你的手机说。
我知道这听起来有点疯狂，
然后会有一种投票机制，
是否会有在Netflix上完全自动生成的节目？
有这种可能，
它会是什么样子？
当你可以按需生成它，并且有无限多的内容时，
这个想法很让人兴奋。
所有的合成内容，
这让人感到谦卑，
因为我们认为自己在创作艺术和想法方面是特殊的，
如果这些能够被AI以自动化方式完成呢？</p><p>我觉得很有趣的是，AI的预测及其未来的样子和能力完全颠倒错位了。</p><p>50年代和60年代的科幻作品完全不准，他们想象中的AI是超级计算理论的证明者，而实际上我们得到的是能够和你谈论情感、进行艺术创作的系统，这实在是奇怪。</p><p>你对AI的发展是否感到兴奋？比如人类和AI系统的混合体谈论情感，像Netflix和AI一起“宅家放松”，甚至连Netflix上的内容也是由AI生成的。</p><p>我认为这将会非常有趣，我对此谨慎乐观，但并不明显。</p><p>让人遗憾的是，你的大脑和我的大脑是在Twitter和互联网出现之前的发展时期形成的。我在想生于互联网时代的人可能会有不同的体验。</p><p>或许我们还会抵制这一变化，而新生代不会。</p><p>我确实觉得人类非常容易改变，你或许是对的。</p><p>安德烈，生活的意义是什么？</p><p>我们谈论了宇宙与我们人类或我们创造的系统之间的对话，试图让宇宙的创造者注意到我们。</p><p>我们试图创建足够响亮的系统来回应。</p><p>我不知道这是否是生活的意义，但这可能是对某些人来说的生活意义。第一个层次的答案是，任何人都可以选择他们自己的生活意义，因为我们是有意识的实体，这很美妙。</p><p>但我确实认为，如果有人感兴趣，生活的一个更深层次的意义是，弄清“这一切究竟是怎么回事，为什么会这样”。如果你研究基本物理学、量子场论和标准模型，你会发现这些非常复杂。</p><p>我们有19个自由参数的宇宙究竟在发生什么，为什么存在？我能破解它吗？我能与它共存吗？它是给我传达某个信息的吗？我是否应该创造一个信息？</p><p>所以我认为在某些基本问题上是有答案的，但我认为实际上你不能在有限的时间内真正对这些问题产生影响。对我来说还有一个大问题就是获得更多的时间，坦率地说。</p><p>是的，这也是我经常思考的问题。因此，最终或至少是首先接近“为什么”问题的方法是尝试逃离这个系统，即宇宙。</p><p>为此你需要倒推说，好吧，这将花费很长时间。所以从工程角度来看，“为什么”问题归结为如何延长时间。</p><p>我认为这是最实际的问题，因为你不会在有限的时间内计算出更深层次的问题答案。这可能是延长你自己的生命，或延长人类文明的寿命，或是谁想要延长谁的寿命。也许很多人不想这么做，但我认为那些想要这么做的人，可能性是存在的。</p><p>我不认为人们完全意识到这一点。我觉得人们将死亡视为不可避免，但最终这只是一个物理系统，有些地方出现了问题，进化论解释了这些现象的原因，肯定有干预措施可以减缓死亡。</p><p>如果死亡最终被认为是人类曾经发生的一件有趣的事情，那将会很有趣。我不认为这是不可能的，我认为这很可能。</p><p>我们可以发挥我们的想象力，试图预测没有死亡的世界是什么样子的。很难说，价值观可能会完全改变。</p><p>我不太相信所有这些观点，即没有死亡就没有意义。我直觉上并不接受这些论点，我认为有很多意义，有很多东西可以学习，它们很有趣，很令人兴奋。我想知道，我想计算，我想改善所有人类和生物的生存状况。</p><p>然而，我们寻找意义的方式可能会改变。很多人，包括我自己，认为事物的有限性中蕴含着意义，但这并不意味着这是唯一的意义源泉。</p><p>我确实认为很多人会选择这种方式，这很好。我喜欢人们能够选择自己的冒险之旅的理念。你作为一个有意识的自由实体出生，我喜欢这么认为，你有不可剥夺的生命权和追求幸福的权利。我不知道你是否在幸福的景观中有这些权利，你大多数时候可以选择你自己的冒险之旅，但这并不完全正确。</p><p>但是我仍然
相当确定我只是一个NPC，但
呃，一个NPC是不可能知道自己是NPC的。
可能会有不同程度和
层次的意识。我认为
没有比这更美好的结尾了。
呃，Andrej，你是一个了不起的人，
我真的很荣幸你愿意和我交流。
你为机器学习领域和人工智能领域所做的贡献，
激励了无数人，教育了数百万人，
真是太棒了，我迫不及待想看到你接下来会做什么。
真的是非常荣幸，谢谢你今天的谈话。
真棒，谢谢你。</p><p>感谢你聆听与Andrej Karpathy的对话，
如果你想支持这个播客，请查看描述中的赞助商。
现在，让我用Samuel Carlin的一些话来结束：
模型的目的是不在于拟合
数据，而在于提炼问题。
谢谢收听，希望下次再见。</p>
    </body>
    </html>
    
